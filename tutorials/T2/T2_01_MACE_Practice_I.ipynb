{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UysH1hGcw9cp"
   },
   "source": [
    "# MACE in Practice I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-zhsj_kw9cx"
   },
   "source": [
    "In this tutorial, you will learn how to fit and test a `MACE` model, which is a highly accurate and efficient MLIP (Machine Learning Interatomic Potential). The training/testing techniques we show here, however, are broadly applicable to all MLIPs. You can independently learn about MACE by studying the [original method paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf). MACE was developed by unifying the Atomic Cluster Expansion (ACE) approach with the Neural Equivariant Interatomic Potentials (NequIP). The mathematical formalism which unifies these methods is explained in the [accompaning paper](https://doi.org/10.48550/arXiv.2205.06643). Another [useful reference](https://doi.org/10.48550/arXiv.2305.14247) showcases the method's performance on published benchmark datasets. The [code implementation](https://github.com/ACEsuit/mace) is publically available and [here](https://mace-docs.readthedocs.io/en/latest/) you can find the documentation. This notebook was made by Ioan MagdÄƒu and Ilyes Batatia and Will Baldwin.\n",
    "\n",
    "### The goal of this notebook is to present all the steps to fitting a MACE potential, from understanding your data, to choosing the right hyper-parameters, testing the model and then running simulations.\n",
    "\n",
    "## Learning Objectives for today:\n",
    "\n",
    "1. **Understanding the data: diverse configs, reference labels**\n",
    "2. **Understanding MACE parameters: architecture and training**\n",
    "3. **Fitting and testing MACE models**\n",
    "4. **Ultimate goal: stable and accurate Molecular Dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOgVCskTDY2A",
    "outputId": "8ea54a04-09fc-48ad-d806-4dd12ce8e533",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIdFlyFDw9cy"
   },
   "source": [
    "## 1. Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aWm7G4Uw9cz"
   },
   "source": [
    "### 1.1 Diverse Molecular Conformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeGzyLq5w9cz"
   },
   "source": [
    "Understanding the data is a crucial part of fitting an MLIP.\n",
    "In this application, we will develop an MLIP for molecular liquids of carbonates. The data presented here is a subset from [this work](https://doi.org/10.1021/acs.jpcb.2c03746) and comprises a mixture of 6 different types of molecules: cyclic carbonates (Vinylene carbonate VC, Ethylene carbonate EC, Propylene carbonate PC) and linear carbonates (Dimethyl carbonate DMC, Ethyl Methyl Carbonate EMC, Diethyl carbonate DEC). Mixtures of these molecules in various formulations are used as solvents in Li-ion battery electrolytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "L7l0qtOVw9cz",
    "outputId": "ba1cc0fa-ce31-4356-92a3-89ba1edbb9ec"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# SMILES strings for each molecule\n",
    "sm_dict = {\n",
    "    'VC': 'c1coc(=O)o1',\n",
    "    'EC': 'C1COC(=O)O1',\n",
    "    'PC': 'CC1COC(=O)O1',\n",
    "    'DMC': 'COC(=O)OC',\n",
    "    'EMC': 'CCOC(=O)OC',\n",
    "    'DEC': 'CCOC(=O)OCC'\n",
    "}\n",
    "\n",
    "Draw.MolsToGridImage([Chem.MolFromSmiles(sm_dict[mol]) for mol in sm_dict], legends=list(sm_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoRoelShw9c0"
   },
   "source": [
    "For this tutorial, we prepared in advance a collection of atomic configurations (small subset from [this paper](https://doi.org/10.1021/acs.jpcb.2c03746)). Let's understand the data! We start by loading the raw configurations with no `labels` (energy, forces). The atomic `configurations`are stored in the [extxyz](https://wiki.fysik.dtu.dk/ase/ase/io/formatoptions.html#extxyz) format and can be accessed using [ASE](https://wiki.fysik.dtu.dk/ase/index.html) as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJXbory9w9c0",
    "outputId": "5adf403e-ded5-4e7b-c878-a45dc905e99a"
   },
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "import numpy as np\n",
    "\n",
    "db = read('data/solvent_configs.xyz', ':') #read in list of configs\n",
    "\n",
    "print(\"Number of configs in database: \", len(db))\n",
    "print(\"Number of atoms in each config: \", np.array([len(at) for at in db]))\n",
    "print(\"Number of atoms in the smallest config: \", np.min([len(at) for at in db])) #test if database contains isolated atoms\n",
    "print(\"Information stored in config.info: \\n\", db[10].info) #check info\n",
    "print(\"Information stored in config.arrays: \\n\", db[10].arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7hs-oo6w9c1"
   },
   "source": [
    "At this point, each configuration is a collection of atoms: atomic number (Z) and positions (R), with no additional information. Let's identify the molecules and label molecular clusters. This will make it easier to inspect the data set and, later, test the accuracy of the potential on describing inter-molecular interactions. Molecule identification is achieved using the `wrap_molecs` function from the [aseMolec package](https://github.com/imagdau/aseMolec), shown here for the first 100 frames `db[:100]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9W62pQUiw9c2",
    "outputId": "69c5c197-ca19-40ec-8877-f9c0baa2cd70"
   },
   "outputs": [],
   "source": [
    "from aseMolec import anaAtoms as aa\n",
    "\n",
    "aa.wrap_molecs(db[:100], prog=False) #identify molecules and label molecular clusters, showcase: first 100 frames\n",
    "# write('data/solvent_molecs.xyz', db) #save full result\n",
    "print(\"Information stored in config.info: \\n\", db[10].info)\n",
    "print(\"Information stored in config.arrays: \\n\", db[10].arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLOruUcDw9c2"
   },
   "source": [
    "Note the additional information for each atomic config: number of molecules `Nmols`, molecular composition `Comp` (e.g `DEC(1):EC(1)` means the config comprises a dimer with 1 DEC molecule and 1 EC molecule) and molecular ID `molID`. Running the code for the full 5000 configurations can be slow, let's just load the final result (`data/solvent_molecs.xyz`) and inspect the distribution of configs by number of molecules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "xwO-WFrGw9c2",
    "outputId": "d40d0f87-87bf-40e1-cd0b-f13764572d40"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "db = read('data/solvent_molecs.xyz', ':')\n",
    "Nmols = np.array([at.info['Nmols'] for at in db]) #collect Nmols information across all data\n",
    "plt.hist(Nmols, align='left', bins=[1,2,3,4,5,6,7], rwidth=0.8);\n",
    "plt.xlabel('# Molecs');\n",
    "plt.ylabel('# Configs comprising that # Molecs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXAaU7D9w9c2"
   },
   "source": [
    "There are just under 1000 configs comprising of single molecules and more than 2000 dimers. The largest configs contain clusters of six molecules.\n",
    "\n",
    "We can check the distribution of molecular compositions for each cluster size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "75WZf4Z2w9c3",
    "outputId": "406e4df6-ec33-45d7-ad91-1776ad349e91"
   },
   "outputs": [],
   "source": [
    "from aseMolec import extAtoms as ea\n",
    "from collections import Counter\n",
    "\n",
    "comp_dict = {} #create a dictionary of compositions for each cluster size\n",
    "for Nmol in range(1,7):\n",
    "    comp_dict[Nmol] = dict(Counter([at.info['Comp'] for at in ea.sel_by_info_val(db, 'Nmols', Nmol)]))\n",
    "\n",
    "Nmol = 6 #show distribution of compositions for cluster size 6\n",
    "plt.pie(comp_dict[Nmol].values(),\n",
    "        labels=comp_dict[Nmol].keys(),\n",
    "        explode=10/(25+np.array(list(comp_dict[Nmol].values()))),\n",
    "        rotatelabels =True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiJzIUwsw9c3"
   },
   "source": [
    "The training set is quite diverse and it contains a good mix of compositions. Check the distribution for other cluster sizes: `Nmol = 1, 2, 3, 4, 5`. Find out if all isolated molecules are present and well sampled. We have six molecules, so there should be 6x7/2 dimers present, are all dimers sampled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWlWPjEnw9c3"
   },
   "source": [
    "### 1.2 Labeling Data with XTB Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAfwvk7ow9c3"
   },
   "source": [
    "We convinced ourselves the training set is quite diverse, it samples many compositions and molecular cluster sizes. It is time to prepare the reference data (energies, forces) to train the model on. We will do this using the Semiempirical Tight Binding level of theory with [XTB](https://xtb-docs.readthedocs.io/en/latest/contents.html). Usually, we would here evaluate an expensive **DFT or quantum chemistry methods**. XTB is much less accurate than these methods for these systems, but it is fast and it will serve as a good example.\n",
    "\n",
    "#### Isolated atoms energies\n",
    "Notice the data set contains isolated molecules but no isolated atoms. MACE (and other MLIPs) fit to atomization energies (eV) which is total energy minus the energy of each atom in vacuum $(E^{0})$:\n",
    "$$\n",
    "E^{\\rm atm} = E^{\\rm tot}-\\sum_i^{N} E^{0}\n",
    "$$\n",
    "It is essential that you compute the energies of the isolated atoms with your reference method on top of the dataset.\n",
    "If you are using a dataset from the internet without that information, we will explain later how MACE can estimate these energies.\n",
    "\n",
    "In our specific example, all molecules comprise of three chemical elements and we will need to compute $(E^{0})$ for each of them:\n",
    "\n",
    "$$\n",
    "E^{\\rm atm} = E^{\\rm tot}-\\sum_i^{N_H} E^{H}_i-\\sum_i^{N_C} E^{C}_i-\\sum_i^{N_O} E^{O}_i\n",
    "$$\n",
    "\n",
    "Let us add three frames containing Hydrogen H, Carbon C and Oxygen O to the dataset and label them as `config_type=IsolatedAtom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqOkFVhow9c3",
    "outputId": "e6558470-88ef-4e6d-8256-5bf4819daeec"
   },
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "db = read('data/solvent_molecs.xyz', ':')\n",
    "db = [Atoms('H'), Atoms('C'), Atoms('O')]+db #add isolated atoms to the database\n",
    "\n",
    "for at in db[:3]:\n",
    "    at.info['config_type'] = 'IsolatedAtom'\n",
    "\n",
    "print(\"Number of configs in database: \", len(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWmVjp8mw9c3"
   },
   "source": [
    "We are now ready to compute the energy and forces with XTB (usually you would run DFT at the stage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVZuM-86w9c3",
    "outputId": "6be7469a-0cda-4465-b291-ef85af2ee58d"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from xtb.ase.calculator import XTB\n",
    "xtb_calc = XTB(method=\"GFN2-xTB\")\n",
    "\n",
    "for at in tqdm(db[:15]): #showcase: first 15 frames\n",
    "    at.calc = xtb_calc\n",
    "    at.info['energy_xtb'] = at.get_potential_energy()\n",
    "    at.arrays['forces_xtb'] = at.get_forces()\n",
    "# write('data/solvent_xtb.xyz', db) #save full result\n",
    "\n",
    "print(\"Information stored in config.info: \\n\", db[13].info) #check info\n",
    "print(\"Information stored in config.arrays: \\n\", db[13].arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIydlj7Tw9c4"
   },
   "source": [
    "The updated data contains one energy value for each config `energy_xtb` and the `forces_xtb` on each atom. Latest version of [ASE](https://wiki.fysik.dtu.dk/ase/index.html) does not support simple names such as `energy` and `forces` so we append `_xtb`. The entire computation takes about `25 mins` for the 5003 configs. We have precomputed the data, so we can simply load the final result. Let's check the $E^0$ values and atomization energies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yms7lVR2w9c4",
    "outputId": "dabe27ab-d42e-413a-f1d8-12340e2be4f5"
   },
   "outputs": [],
   "source": [
    "db = read('data/solvent_xtb.xyz', ':15')\n",
    "\n",
    "print(\"E0s: \\n\", ea.get_E0(db, tag='_xtb'))\n",
    "print(\"Total energy per config: \\n\", ea.get_prop(db, 'info', 'energy_xtb', peratom=False)[13])\n",
    "print(\"Toal energy per atom: \\n\", ea.get_prop(db, 'info', 'energy_xtb', peratom=True)[13])\n",
    "print(\"Atomization energy per config: \\n\", ea.get_prop(db, 'bind', prop='_xtb', peratom=False)[13])\n",
    "print(\"Atomization energy per atom: \\n\", ea.get_prop(db, 'bind', prop='_xtb', peratom=True)[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_JwelBsw9c4"
   },
   "source": [
    "Good! We get about -6 $\\rm eV/atom$ which is largely dominated by the energy of the [covalent bonds](https://en.wikipedia.org/wiki/Bond-dissociation_energy#:~:text=of%20a%20solvent.-,Representative%20bond%20enthalpies,-%5Bedit%5D). Remember, the largest contribution to the total energy comes from $E^0$ and then from covalent bonds. The noncovalent interactions contribute a very small amount to the total energy, yet they are crucial for molecular dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js5fVTG5w9c4"
   },
   "source": [
    "## 2. Understanding MACE hyper parameters and interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhHuQR5wDVlk"
   },
   "source": [
    "In order to train a MACE potential, one needs to create a configuration file that specifies three kind of information:\n",
    " 1. Choice your model hyper-parameters.\n",
    " 2. Specification of the data.\n",
    " 3. Selection of your optimization parameters.\n",
    "\n",
    "These informations are required in order to call the mace training script called `mace_run_train`.\n",
    "\n",
    "The following section will cover in detail all of these three steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj3O9iqFw9c4"
   },
   "source": [
    "### 2.1 Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q-ar1-Rw9c5"
   },
   "source": [
    "MACE has different hyper parameters that controls the degree of accuracy and expressivity of the model. Setting these parameters is a trade off between accuracy and computational cost. Most MACE parameters have robust and well tested defaults. We call them here \"Parameters to keep to default values\" but mention them for general knowledge. The \"Hyper Parameters to Change\" are hyper parameters that need to be adjusted as they can be task or system dependent.\n",
    "\n",
    "### Hyper Parameters to Change:\n",
    "\n",
    "- **`--num_channels`: Number of channels**\n",
    "  \n",
    "  Determines the size of the model. The recommended value is `--num_channels=128` but other potential values are `64` for a faster model or `256` for a large but more accurate model.\n",
    "  \n",
    "  \n",
    "- **`max_L`: Symmetry of the messages**\n",
    "\n",
    "  Determines the symmetry of the messages. A value of `--max_L=0` means MACE will pass only invariant information between neigborhoods. It is the parameter **that affects the most the computational speed and the accuracy of the model**. `--max_L=0` are the fastest model, use them to train cheap model to run large and long simulations. `--max_L=1` is the default value, it is a good compromise between speed and accuracy. It is recommended to start with that value for a new project. `--max_L=2` are the most accurate models, use them to train very accurate but slower models.\n",
    "  \n",
    "\n",
    "- **`--r_max`: The cutoff radius**\n",
    "  \n",
    "  The cutoff used to create the local environment in each layer. `r_max=5.0` means atoms separated by a distance of more than 5.0 Ã… do not directly communicate in a single layer. When the model has multiple message-passing layers, atoms further than 5.0 Ã… can still communicate through later messages if intermediate proxy atoms exist. The effective receptive field of the model is `num_interactions * r_max`. The larger the `r_max`, the slower the model will be. It is recommended to use values between 4.0 Ã… and 7.0 Ã….\n",
    "\n",
    "---\n",
    "\n",
    "### Hyper Parameters to keep to default values (for general knowledge):\n",
    "\n",
    "- **`--num_interactions`: Message-passing layers**\n",
    "  \n",
    "  Controls the number of message-passing layers in the model. It should always be 2, and it is recommended not to modify it.\n",
    "\n",
    "\n",
    "- **`--correlation`: The order of the many-body expansion**\n",
    "\n",
    "  The body order that MACE induces at each layer. Choosing `--correlation=3` will create basis functions of up to 4-body (ijkl) indices, for each layer. If the model has multiple layers, the effective correlation order is higher. For example, a two-layer MACE with `--correlation=3` has an effective body order of 13.\n",
    "\n",
    "\n",
    "- **`--max_ell`: Angular resolution**\n",
    "\n",
    "  The angular resolution describes how well the model can describe angles. This is controlled by `max_ell` of the spherical harmonics basis (not to be confused with `max_L`). Larger values will result in more accurate but slower models. The default is `max_ell=3`, which is appropriate in most cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNsWqhcsw9c5"
   },
   "source": [
    "### 2.2 Optimization and data management parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_tfIjBvw9c6"
   },
   "source": [
    "### General training management:\n",
    "\n",
    "\n",
    "- ##### `--name`: the name of the model\n",
    "    This name will be used to form file names (model, log, checkpoints, results), so choose a distinct name for each experiment\n",
    "\n",
    "- ##### `--model_dir, --log_dir, --checkpoints_dir, --results_dir`: directory paths\n",
    "    These are the directories where each type of file is saved. For simplicity, we will save all files in the same directory.\n",
    "\n",
    "### Data management:\n",
    "\n",
    "- ##### `--train_file`: name of training dataset\n",
    "\n",
    "    These are the configurations that will be use to train the model.\n",
    "\n",
    "- ##### `--valid_file`: name of validation dataset\n",
    "    An alternative way to choose the validation set is by using the `--valid_fraction` keyword. These data configs are used to estimate the model accuracy during training, but not for parameter optimization. The validation set also controls the stopping of the training. At each `--eval_interval` the model is tested on the validation set. The evaluation of these configs takes place in batches, which can be controlled by `--valid_batch_size`. If the accuracy of the model stops improving on the validation set for `--patience` number of epochs, the model will undergo **early stopping**.\n",
    "\n",
    "- ##### `--test_file`: name of testing dataset\n",
    "\n",
    "    This set is entirely independent and only gets evaluated at the end of the training process to estimate the model accuracy on an independent set.\n",
    "\n",
    "- ##### `--E0s`: isolated atom energies\n",
    "\n",
    "    Controls how `E0s` should be determined. The strongly recommended approach is to add these values to the training set with `config_type=IsolatedAtom` in `atoms.info` and set `E0s=\"isolated\"`. If these values are not available, MACE can estimate them by least square regression over the available data `E0s=\"average\"` which can lead to unintended consequences depending on how representative the data is.\n",
    "\n",
    "- ##### `--energy_key, --forces_key` the key where these values are stores\n",
    "    This key must coincide with the `ase.Atoms.info[key]/ase.Atoms.arrays[key]` where the energies and forces are stored in the ase.Atoms object. **It is very important to get them right**.\n",
    "\n",
    "### Optimization:\n",
    "\n",
    "- ##### `--device` computing device to use\n",
    "    Can be CPU (`cpu`), GPU (`cuda`) or Apple Silicon (`mps`). Here we will use `cuda` since the GPU will be significantly faster than the CPU.\n",
    "\n",
    "- ##### `--batch_size` number of configs evaluated in one batch\n",
    "    Number of configs used to compute the gradients for each full update of the network parameters. This training strategy is called stochastic gradient descent because only a subset of the data (`batch_size`) is used to change the parameters at each update.\n",
    "\n",
    "- ##### `--max_num_epochs` number of passes through the data\n",
    "    An `epoch` is completed when the entire training data has been used once in updating the weights `batch` by `batch`. A new epoch begins, and the process repeats.\n",
    "\n",
    "- ##### `--swa` protocol for loss weights\n",
    "    During training you will notice energy errors are at first much higher than force errors, MACE implements a special protocol that increases the weight on the energy in the loss function (`--swa_energy_weight`) once the forces are sufficiently accurate. The starting epoch for this special protocol can be controlled by changing `--start_swa`.\n",
    "\n",
    "- ##### `--seed` random number generator seed\n",
    "    Useful for preparing committee of models.\n",
    "\n",
    "**Now we are ready to fit our first MACE model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XpbIFivw9c6"
   },
   "source": [
    "## 3. Fitting and Testing MACE models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXd-S4nODVll"
   },
   "source": [
    "**Let's fit our first MACE model to our data.**\n",
    "\n",
    "Let's start by splitting the data into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2V2ul6dtDVll"
   },
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "\n",
    "db = read('data/solvent_xtb.xyz', ':')\n",
    "write('data/solvent_xtb_train_200.xyz', db[:203]) #first 200 configs plus the 3 E0s\n",
    "write('data/solvent_xtb_test.xyz', db[-1000:]) #last 1000 configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foM9J3rPw9c6"
   },
   "source": [
    "### 3.1 Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4X_7Y8mdDVlm"
   },
   "source": [
    "We will now write our first configuration file, that contains all the information detailed above. This a template you can adapt to your own data later on. We will create a small invariant model in order to run fast in the limited time we have. **Try to understand each of the entries by looking at their explanations above**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FK447de6w9c6",
    "outputId": "5e98ad82-ff5c-46f5-b8f2-51d2eb988653"
   },
   "outputs": [],
   "source": [
    "%%writefile config/config-02.yml\n",
    "\n",
    "model: \"MACE\"\n",
    "num_channels: 32\n",
    "max_L: 0\n",
    "r_max: 4.0\n",
    "name: \"mace01\"\n",
    "model_dir: \"MACE_models\"\n",
    "log_dir: \"MACE_models\"\n",
    "checkpoints_dir: \"MACE_models\"\n",
    "results_dir: \"MACE_models\"\n",
    "train_file: \"data/solvent_xtb_train_200.xyz\"\n",
    "valid_fraction: 0.10\n",
    "test_file: \"data/solvent_xtb_test.xyz\"\n",
    "energy_key: \"energy_xtb\"\n",
    "forces_key: \"forces_xtb\"\n",
    "device: cuda\n",
    "batch_size: 10\n",
    "max_num_epochs: 100\n",
    "swa: True\n",
    "seed: 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCvWWw3TDVlm"
   },
   "source": [
    "Normally you would call a script from the command line called `mace_run_train` (see https://mace-docs.readthedocs.io/en/latest/guide/training.html) and pass it a yaml file of parameters. Below we define a function to train mace from inside python instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueQqBjhRDVlm",
    "outputId": "bbc31413-6916-4d62-906d-d1e6a51004f5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mace.cli.run_train import main as mace_run_train_main\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "def train_mace(config_file_path):\n",
    "    logging.getLogger().handlers.clear()\n",
    "    sys.argv = [\"program\", \"--config\", config_file_path]\n",
    "    mace_run_train_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoYYvmRuDVln",
    "outputId": "f9cae4ce-182e-4dde-d618-75f975b5d9c2"
   },
   "outputs": [],
   "source": [
    "train_mace(\"config/config-02.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_SwVO4rDVln"
   },
   "source": [
    "***Congratulations you have trained your first MACE model!!!***\n",
    "**Extra: you can try to run new training by changing the model sizes and look at how it affects the accuracy in the final table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJFppol1w9c7"
   },
   "outputs": [],
   "source": [
    "#remove checkpoints since they may cause errors on retraining a model with the same name but a different architecture\n",
    "import glob\n",
    "import os\n",
    "for file in glob.glob(\"MACE_models/*.pt\"):\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9Pnl7VWw9c7"
   },
   "source": [
    "##### **Question: Here we trained on a very small subset of the data, repeat training for 400, 1000, 2000, 4000 data points, remember to change the name of the model accordingly. How does the learning curve (test error vs size of training test) look like?** `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5CZIuoDw9dA"
   },
   "source": [
    "### 3.2 Testing the model: simple RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBoDXBvvDVln"
   },
   "source": [
    "Use the `mace_eval_configs` script to evaluate the trained model on both the train and test datasets. The script takes the arguments: `--configs` which specifies the file to evaluate, the path to the model in `--model` and the path to the output in `--output`. Here we call it from python again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "843KuGFxDVlo"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.makedirs(\"tests/mace01/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AQ_IwhPDVlo"
   },
   "outputs": [],
   "source": [
    "from mace.cli.eval_configs import main as mace_eval_configs_main\n",
    "import sys\n",
    "\n",
    "def eval_mace(configs, model, output):\n",
    "    sys.argv = [\"program\", \"--configs\", configs, \"--model\", model, \"--output\", output]\n",
    "    mace_eval_configs_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2A019Sdw9dA",
    "outputId": "726df494-8398-4920-c2c3-b2daa075ca7b"
   },
   "outputs": [],
   "source": [
    "#evaluate the training set\n",
    "eval_mace(configs=\"data/solvent_xtb_train_200.xyz\",\n",
    "          model=\"MACE_models/mace01_run-123_stagetwo.model\",\n",
    "          output=\"tests/mace01/solvent_train.xyz\")\n",
    "\n",
    "#evaluate the test set\n",
    "eval_mace(configs=\"data/solvent_xtb_test.xyz\",\n",
    "          model=\"MACE_models/mace01_run-123_stagetwo.model\",\n",
    "          output=\"tests/mace01/solvent_test.xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pb-JDH2Fw9dA"
   },
   "source": [
    "We can compare MACE vs XTB accuracy on the train and test sets and for this we will use the [aseMolec](git@github.com:imagdau/aseMolec.git) which implements some handy utilities for manipulating ase.Atoms and testing potentials, especially for molecular systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "VWZlt-Nww9dA",
    "outputId": "2172fa1b-f078-4ece-ca42-7ef96d67d39d"
   },
   "outputs": [],
   "source": [
    "from aseMolec import pltProps as pp\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "from aseMolec import extAtoms as ea\n",
    "import numpy as np\n",
    "\n",
    "def plot_RMSEs(db, labs):\n",
    "    ea.rename_prop_tag(db, 'MACE_energy', 'energy_mace') #Backward compatibility\n",
    "    ea.rename_prop_tag(db, 'MACE_forces', 'forces_mace') #Backward compatibility\n",
    "\n",
    "    plt.figure(figsize=(9,6), dpi=100)\n",
    "    plt.subplot(1,3,1)\n",
    "    pp.plot_prop(ea.get_prop(db, 'bind', '_xtb', True).flatten(), \\\n",
    "                 ea.get_prop(db, 'bind', '_mace', True).flatten(), \\\n",
    "                 title=r'Energy $(\\rm eV/atom)$ ', labs=labs, rel=False)\n",
    "    plt.subplot(1,3,2)\n",
    "    pp.plot_prop(ea.get_prop(db, 'info', 'energy_xtb', True).flatten(), \\\n",
    "                 ea.get_prop(db, 'info', 'energy_mace', True).flatten(), \\\n",
    "                 title=r'Energy $(\\rm eV/atom)$ ', labs=labs, rel=False)\n",
    "    plt.subplot(1,3,3)\n",
    "    pp.plot_prop(np.concatenate(ea.get_prop(db, 'arrays', 'forces_xtb')).flatten(), \\\n",
    "                 np.concatenate(ea.get_prop(db, 'arrays', 'forces_mace')).flatten(), \\\n",
    "                 title=r'Forces $\\rm (eV/\\AA)$ ', labs=labs, rel=False)\n",
    "    plt.tight_layout()\n",
    "    return\n",
    "\n",
    "train_data = read('tests/mace01/solvent_train.xyz', ':')\n",
    "test_data = train_data[:3]+read('tests/mace01/solvent_test.xyz', ':') #append the E0s for computing atomization energy errors\n",
    "\n",
    "plot_RMSEs(train_data, labs=['XTB', 'MACE'])\n",
    "plot_RMSEs(test_data, labs=['XTB', 'MACE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v75wGSfOw9dA"
   },
   "source": [
    "These figures show correlation plots between XTB values and MACE predicted values for atomization energy per atom, the total energy per atom and forces. Do the RMSE values match the number printed at the end of the model training? These errors don't look too bad, and this MACE is a small model with few parameters. Significantly better accuracies can be achieved when training on larger models with more data. How does your model trained on 4000 configs compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mjpBhh1w9dA"
   },
   "source": [
    "### 3.3 Testing on the Intra/Inter decomposition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IoqQlSSw9dB"
   },
   "source": [
    "As shown in this [paper](https://doi.org/10.1038/s41524-023-01100-w) one of the challenges associated with modelling molecular systems has to do with the  inter-molecular interactions.\n",
    "Molecular dynamics is primarily driven by these inter-molecular interactions, however they are relatively small in comparison to covalent interactions and prove difficult to capture with MLIPs.\n",
    "The paper introduces this protocol to decompose the force errors into [intra- and inter-] molecular RMSEs to gauge the quality of the potential separately on the two interaction scales. This approach can be summarized as follows:\n",
    "1. Identify molecules (labeled **j**).  \n",
    "\n",
    "2. Within each molecule **j** sum over all atomic forces (labeled **k**) to obtain the **translational** component:\n",
    "$$F^{\\rm trans}_j = \\sum_{k \\in j} f_{k}$$\n",
    "\n",
    "3. Redistribute the molecular **translational** force onto individual atoms (labeled **i**) to obtain the atomic **translational** contributions:\n",
    "$$f^{\\rm trans}_i = \\frac{m_i}{M_j} F^{\\rm trans}_j$$\n",
    "\n",
    "4. Similarly, compute the torque on the entire molecule:\n",
    "$$T_j = \\sum_{k \\in j} f_{k} \\times r_{k}$$\n",
    "\n",
    "5. Compute the atomic **rotational** force contributions that give rise to the given molecular torque:\n",
    "$$f^{\\rm rot}_i = m_i r_i \\times (I_j^{\\alpha \\beta})^{-1} T_j$$\n",
    "\n",
    "6. Finally compute the **vibrational** contribution as the difference:\n",
    "$$f^{\\rm vib}_i = f_i - f^{\\rm trans}_i - f^{\\rm rot}_i$$\n",
    "\n",
    "7. In this approach, the **Inter** is the sum of `trans` and `rot`, while the **Intra** is the `vib` component.\n",
    "\n",
    "This force decomposition can be automatically obtained using the [aseMolec](https://github.com/imagdau/aseMolec) package as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "195Ic7eqw9dB",
    "outputId": "9ed3ea97-4350-40d4-c437-1a8d49eb9c67"
   },
   "outputs": [],
   "source": [
    "from aseMolec import pltProps as pp\n",
    "from aseMolec import anaAtoms as aa\n",
    "\n",
    "db1 = read('tests/mace01/solvent_test.xyz', ':')\n",
    "ea.rename_prop_tag(db1, 'energy_xtb', 'energy') #Backward compatibility\n",
    "ea.rename_prop_tag(db1, 'forces_xtb', 'forces') #Backward compatibility\n",
    "\n",
    "db2 = read('tests/mace01/solvent_test.xyz', ':')\n",
    "ea.rename_prop_tag(db2, 'MACE_energy', 'energy') #Backward compatibility\n",
    "ea.rename_prop_tag(db2, 'MACE_forces', 'forces') #Backward compatibility\n",
    "\n",
    "aa.extract_molecs(db1, intra_inter=True)\n",
    "aa.extract_molecs(db2, intra_inter=True)\n",
    "\n",
    "pp.plot_trans_rot_vib(db1, db2, labs=['XTB', 'MACE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYwzzzE6w9dB"
   },
   "source": [
    "Indeed, the translation and rotational part of the forces (related to inter-molecular interactions) is significantly harder to capture as evidenced by the larger errors. While the absolute RMSEs are smaller, the relative RMSEs are signifincatly larger for the inter-molecular components. Nevertheless, MACE errors are significantly lower than other models on these tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vIo2Hrtw9dB"
   },
   "source": [
    "## 4. Molecular Dynamics with MACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umrotldfDVlp"
   },
   "source": [
    "**Let's run your first simulation with MACE in ASE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG0JbYzZw9dB"
   },
   "source": [
    "### 4.1 Is the dynamics stable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhuu8Tkzw9dB"
   },
   "source": [
    "Accuracy on fixed test sets is great, but molecular dynamics (MD) is the ultimate test. First, we care about stability, then accuracy: let's check if MACE gives stable dynamics. We will start by implementing a simple function to run Langevin dynamics. We initialize the temperature at 300 K and remove all translations and rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb3g5X2Jw9dB"
   },
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "from ase import units\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.velocitydistribution import Stationary, ZeroRotation, MaxwellBoltzmannDistribution\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "def simpleMD(init_conf, temp, calc, fname, s, T):\n",
    "    init_conf.set_calculator(calc)\n",
    "\n",
    "    #initialize the temperature\n",
    "    random.seed(701) #just making sure the MD failure is reproducible\n",
    "    MaxwellBoltzmannDistribution(init_conf, temperature_K=300) #initialize temperature at 300\n",
    "    Stationary(init_conf)\n",
    "    ZeroRotation(init_conf)\n",
    "\n",
    "    dyn = Langevin(init_conf, 1.0*units.fs, temperature_K=temp, friction=0.1) #drive system to desired temperature\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    time_fs = []\n",
    "    temperature = []\n",
    "    energies = []\n",
    "\n",
    "    #remove previously stored trajectory with the same name\n",
    "    os.system('rm -rfv '+fname)\n",
    "\n",
    "    fig, ax = pl.subplots(2, 1, figsize=(6,6), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "    def write_frame():\n",
    "            dyn.atoms.write(fname, append=True)\n",
    "            time_fs.append(dyn.get_time()/units.fs)\n",
    "            temperature.append(dyn.atoms.get_temperature())\n",
    "            energies.append(dyn.atoms.get_potential_energy()/len(dyn.atoms))\n",
    "\n",
    "            ax[0].plot(np.array(time_fs), np.array(energies), color=\"b\")\n",
    "            ax[0].set_ylabel('E (eV/atom)')\n",
    "\n",
    "            # plot the temperature of the system as subplots\n",
    "            ax[1].plot(np.array(time_fs), temperature, color=\"r\")\n",
    "            ax[1].set_ylabel('T (K)')\n",
    "            ax[1].set_xlabel('Time (fs)')\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(pl.gcf())\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    dyn.attach(write_frame, interval=s)\n",
    "    t0 = time.time()\n",
    "    dyn.run(T)\n",
    "    t1 = time.time()\n",
    "    print(\"MD finished in {0:.2f} minutes!\".format((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXkvPxg_w9dC"
   },
   "source": [
    "Now we can run MD with MACE and compare it to the XTB dynamics. Let's try 2 picoseoncds at 1200 K, starting from a single molecule config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V_pWO0Y5w9dC",
    "outputId": "7aba417f-c77b-4071-b491-495ffe097df7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " #let us start with a single molecule\n",
    "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
    "\n",
    "#we can use MACE as a calculator in ASE!\n",
    "from mace.calculators import MACECalculator\n",
    "mace_calc = MACECalculator(model_paths=['MACE_models/mace01_run-123_stagetwo.model'], device='cuda', default_dtype=\"float32\")\n",
    "\n",
    "simpleMD(init_conf, temp=1200, calc=mace_calc, fname='moldyn/mace01_md.xyz', s=10, T=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from x3dase.x3d import write_x3d\n",
    "\n",
    "traj = read('moldyn/mace01_md.xyz', index=':')\n",
    "write_x3d(atoms=traj, filename='mace01_md.html')\n",
    "\n",
    "# Find the mace01_md.html file on the left-hand side, double click on it\n",
    "# Click Trust HTML in the top-left corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvBGndtOw9dD"
   },
   "source": [
    "For reference, we can also run XTB dynamics from the same starting configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WYr2jodXw9dD",
    "outputId": "d960a6c2-0bdc-4a67-925e-cfefb180546a"
   },
   "outputs": [],
   "source": [
    "# reinitialize the original config\n",
    "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
    "\n",
    "from xtb.ase.calculator import XTB\n",
    "xtb_calc = XTB(method=\"GFN2-xTB\")\n",
    "\n",
    "simpleMD(init_conf, temp=1200, calc=xtb_calc, fname='moldyn/xtb_md_2.xyz', s=10, T=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKcExFCYw9dD"
   },
   "source": [
    "MACE dynamics finished in under 2 minutes, vs XTB would take over 14, so we stop after just 200 steps. This is the essence of MLIP: speeding up calculations that would otherwise take a long time to run. In this case, the speed-up is just one order of magnitude, but depending on the cost of the reference calculation, it can be many orders of magnitude for expensive Quantum Chemistry methods and large systems. Remember, the cost of MLIP is independent of the accuracy of the potential energy surface!\n",
    "\n",
    "Let's visualize the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4S6wYLbw9dD",
    "outputId": "138676b4-17f2-43d8-a09e-c348ffc61d2a"
   },
   "outputs": [],
   "source": [
    "from x3dase.x3d import write_x3d\n",
    "\n",
    "traj = read('moldyn/xtb_md_2.xyz', ':')\n",
    "write_x3d(atoms=traj, filename='xtb_md_2.html')\n",
    "\n",
    "# Find the xtb_md_2.html file on the left-hand side, double click on it\n",
    "# Click Trust HTML in the top-left corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt897i7fw9dD"
   },
   "source": [
    "\n",
    "Obtaining stable dynamics with so little training is a great result. Up until recently, most MLIPs would require a lot of training before MD was stable. MACE combines the lessons learned over 10-15 years in MLIP development, to achieve a smooth and regular potential energy surface, which minimizes the risk of unstable MD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOhT8asgw9dE"
   },
   "source": [
    "### 4.2 Is the dynamics accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrZau3elw9dE"
   },
   "source": [
    "Are the different dynamics sampling the correct distributions? Let us check the radial distribution functions (RDF). The [aseMolec](https://github.com/imagdau/aseMolec) package provides functionality to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2JQJmXtw9dE",
    "outputId": "4c6c3825-5408-4c17-a24f-b5b98dfe46a0"
   },
   "outputs": [],
   "source": [
    "from aseMolec import anaAtoms as aa\n",
    "\n",
    "tag = 'HO_intra' #choose one of 'HH_intra', 'HC_intra', 'HO_intra', 'CC_intra', 'CO_intra', 'OO_intra'\n",
    "\n",
    "for f in ['xtb_md', 'mace01_md']:\n",
    "    traj = read('moldyn/'+f+'.xyz', '50:') #ignore first 50 frames\n",
    "    for at in traj:\n",
    "        at.pbc = True #create a fake box for rdf compatibility\n",
    "        at.cell = [100,100,100]\n",
    "    rdf = aa.compute_rdfs_traj_avg(traj, rmax=5, nbins=50) #aseMolec provides functionality to compute RDFs\n",
    "    plt.plot(rdf[1], rdf[0][tag], '.-', label=f, alpha=0.7, linewidth=3)\n",
    "\n",
    "plt.legend();\n",
    "plt.yticks([]);\n",
    "plt.xlabel(r'R ($\\rm \\AA$)');\n",
    "plt.ylabel('RDF '+tag);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zliGPu7Vw9dE"
   },
   "source": [
    "Try it yourself! Inspect other RDF pairs (`C-O`, `H-C`), how well are they reproduced?\n",
    "\n",
    "The trajectories here are stable and also quite accurate. This is still a relatively simple task: we chose a single molecule at relatively small temperatures (for a molecule) and only ran for 2 picoseconds. In practice, given enough time and high enough temperature the initial models will fail.\n",
    "\n",
    "Experiment with the starting configs, temperatures, simulation length, see if you can find problems with the potentials!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6S4gXPPw9dF"
   },
   "source": [
    "### 4.3 MD of a molecular liquid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68B-kPqkw9dF"
   },
   "source": [
    "The MLIP was trained on clusters, can we simulate the liquid molecular environment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NsydgLBmw9dF",
    "outputId": "9945499f-724c-499f-e33f-a472e3020792"
   },
   "outputs": [],
   "source": [
    "init_conf = read('data/solvent_liquid.xyz') #read a liquid config with periodic boundary conditions\n",
    "init_conf.center()\n",
    "simpleMD(init_conf, temp=500, calc=mace_calc, fname='moldyn/mace01_md_liquid.xyz', s=10, T=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEeLK9QCw9dG"
   },
   "source": [
    "This XTB calculator is non-periodic, so this dynamics would not be possible without an MLIP! Check for yourself, by replacing the calculator with `xtb`. The system is much larger than the example before (12 molecules vs just one). Let's view the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FH3NUDXOw9dG",
    "outputId": "06d35827-9b2d-4a4f-d013-1307b3998af1"
   },
   "outputs": [],
   "source": [
    "from x3dase.x3d import write_x3d\n",
    "\n",
    "traj = read('moldyn/mace01_md_liquid.xyz', ':')\n",
    "write_x3d(atoms=traj, filename='mace01_md_liquid.html')\n",
    "\n",
    "# Find the mace01_md_liquid.html file on the left-hand side, double click on it\n",
    "# Click Trust HTML in the top-left corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPOHzV51w9dG"
   },
   "source": [
    "Transferability from clusters to the condensed phase environment is still an [open research](https://doi.org/10.1021/acs.jpcb.2c03746) question. If this works, it implies that we might be able to learn highly accurate Quantum Chemistry PES on molecular clusters and make predictions (density, diffusivity) for the condensed phase! This is new science!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2a16e1e8a7ad42a8825007f5cff15d19",
  "kernelspec": {
   "display_name": "T2",
   "language": "python",
   "name": "t2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
