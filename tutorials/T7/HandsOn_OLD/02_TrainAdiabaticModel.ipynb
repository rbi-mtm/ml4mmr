{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ae4ffa-616f-4fea-8687-ce7650016ce8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903dbc06-3fcf-477c-8ed6-358247ec2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NFF package from path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./NFF\")\n",
    "from nff.data import Dataset, collate_dicts\n",
    "from nff.train import Trainer, get_model, loss, hooks, metrics, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178abb7e-fa63-4eb6-849d-aac0055f005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from evaluate import make_scatterplot, get_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d0a48-4103-4771-817e-c532ffa14b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder\n",
    "OUTDIR = \"./Model_Adiabatic\"\n",
    "# make subfolders\n",
    "try:\n",
    "    os.makedirs(os.path.join(OUTDIR, \"0\"))\n",
    "except:\n",
    "    print(\"The folders already exists! This will overwrite what has been written there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815fd4b-60c0-41ee-8337-f5ed213c96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CUDA as a device if available\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6ea50-5f26-4302-bc5e-ea1b73041eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train = Dataset.from_file('./train.pth.tar')\n",
    "test = Dataset.from_file('./test.pth.tar')\n",
    "val = Dataset.from_file('./val.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e8c7b-3500-4dcd-9a95-686dd2868622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the output keys\n",
    "output_keys = []\n",
    "grad_keys = []\n",
    "for i in range(3):\n",
    "    output_keys.append(f\"energy_{i}\")\n",
    "    grad_keys.append(f\"energy_{i}_grad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049894e9-cf12-4b99-aeb1-dd62d8672581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and updateparameters\n",
    "with open(\"./default_params.json\", 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "params.update({\"compute_delta\": False,\n",
    "                \"output_keys\": output_keys,\n",
    "                \"grad_keys\": grad_keys,\n",
    "                'details': None})\n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(params, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(os.path.join(OUTDIR, \"params.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9263f9-0252-4b66-a2c8-3abb76fa8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "# MSE loss for energies and forces with a weighting 1:10\n",
    "# and additionally an MAE loss on the energy gap between neighbouring adiabatic states\n",
    "multi_loss_dict = {\"mse\": [{\"coef\": 0.1, \"params\": {\"key\": key, \"loss_type\": \"mae\",}} for key in output_keys]+\n",
    "                   [{\"coef\": 1.0, \"params\": {\"key\": key, \"loss_type\": \"mse\",}} for key in grad_keys],\n",
    "                   #\"diff\": [{\"coef\": 0.1, \"params\": {\"keys\": [output_keys[ii+1], output_keys[ii]], \"loss_type\": \"mae\",}} for ii in range(len(output_keys)-1) if \"energy_S\" in output_keys[ii+1] ]\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818d07d-837f-4f76-954e-8501749e50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metric is the MAE, logged while training\n",
    "train_metrics = [\n",
    "    metrics.MeanAbsoluteError(outkey) for outkey in output_keys]\n",
    "train_metrics += [\n",
    "    metrics.MeanAbsoluteError(outkey) for outkey in grad_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e70a0c-4fe0-48ee-8dd0-3569c0863686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make torch loaders for the splits\n",
    "train_loader = DataLoader(train, batch_size=params['batch_size'], collate_fn=collate_dicts)\n",
    "val_loader = DataLoader(val, batch_size=params['batch_size'], collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=params['batch_size'], collate_fn=collate_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37094de5-3459-4415-85db-4939af3ec9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate a new model\n",
    "model = get_model(params, model_type=\"Painn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf69fd-4485-4a9a-85a4-69f0a6158b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize new optimzers etc.\n",
    "loss_fn = loss.build_multi_loss(multi_loss_dict = multi_loss_dict)\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = Adam(trainable_params, lr=params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363d38f-a503-4236-bf3c-37178c8a11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hooks, maximum number of epochs, how to change learning rate depending on convergence\n",
    "train_hooks = [\n",
    "hooks.MaxEpochHook(params['max_epochs']),\n",
    "hooks.CSVHook(\n",
    "    OUTDIR,\n",
    "    metrics=train_metrics,\n",
    "    ),\n",
    "    hooks.PrintingHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "        separator = ' | ',\n",
    "        time_strf='%M:%S'\n",
    "    ),\n",
    "hooks.ReduceLROnPlateauHook(\n",
    "        optimizer=optimizer,\n",
    "        patience=params['lr_patience'],\n",
    "        factor=params['lr_decay'],\n",
    "        min_lr=params['lr_min'],\n",
    "        window_length=1,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2782ff9-efaa-4a85-931e-ed9be5ff14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trainer class\n",
    "T = Trainer(\n",
    "model_path=OUTDIR,\n",
    "model=model,\n",
    "loss_fn=loss_fn,\n",
    "optimizer=optimizer,\n",
    "train_loader=train_loader,\n",
    "validation_loader=val_loader,\n",
    "checkpoint_interval=1,\n",
    "hooks=train_hooks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5d9c7-db4e-44f1-b25a-82d8d0064e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do the actual training\n",
    "T.train(device=DEVICE, n_epochs=params['max_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa89866-b0c4-4ac6-9827-d663785ead8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(os.path.join(OUTDIR, 'log.csv'))\n",
    "metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f82f3-4cb2-453c-816c-74b7ac7c271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14,5), sharex=True, sharey=False)\n",
    "\n",
    "blues = ['#00429d', '#346cc2', '#5399e8']\n",
    "reds = ['#94003a', '#c82c46', '#ff4e52']\n",
    "\n",
    "axs[0].plot(metrics['Train loss'], label='Train loss')\n",
    "axs[0].plot(metrics['Validation loss'], label='Val loss')\n",
    "\n",
    "for state in range(3):\n",
    "    axs[1].plot(metrics[f'MAE_energy_{state}'], label=f'S{state}', color=blues[state])\n",
    "    axs[2].plot(metrics[f'MAE_energy_{state}_grad'], label=f'S{state}', color=reds[state])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='y',length=6,width=3,labelsize=20, pad=10, direction='in')\n",
    "    ax.tick_params(axis='x',length=6,width=3,labelsize=20, pad=10, direction='in')\n",
    "    for key in ax.spines.keys():\n",
    "        ax.spines[key].set_linewidth(3)\n",
    "    #ax.set_ylim([0, 0.5])\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=20)\n",
    "    ax.legend(frameon=False, fontsize=16)\n",
    "\n",
    "axs[1].set_title(\"Energy MAE\", fontsize=20)\n",
    "axs[2].set_title(\"Forces MAE\", fontsize=20)\n",
    "axs[0].set_ylabel(r\"Error\", fontsize=20)\n",
    "\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(os.path.join(OUTDIR, \"learning_curve.png\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb362408-d0bf-4a86-ba9c-15c889a204e2",
   "metadata": {},
   "source": [
    "## Calculate Test Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cfe79-f851-487b-a794-dcdddbfbd5c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_targets_testloss = evaluate(T.get_best_model(), test_loader, loss_fn, device=DEVICE)\n",
    "pred_dict, targ_dict, _ = results_targets_testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafba100-6264-48b0-8657-84ef9fb2f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = get_stats(targ_dict, pred_dict, output_keys, grad_keys)\n",
    "# Serializing json\n",
    "json_object = json.dumps(test_stats, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(os.path.join(OUTDIR, \"evaluate.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481bcad-58d1-46ff-b70b-b8257d46fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_stats['energy'])\n",
    "print(test_stats['delta_energy'])\n",
    "print(test_stats['energy_grad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e110d-6e06-4ac8-a78d-8e535ed46962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_scatterplot(os.path.join(OUTDIR, \"Scatter_Test.png\"), \n",
    "                    targ_dict,\n",
    "                    pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e136c5-5678-4acd-86c1-2bb2e2c90ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c45f8-de08-48a4-be8e-21a3d400dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
