{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we describe a focused AI approach for modeling heterogeneous catalysts based on subgroup discovery (SGD) and on the sure-independence screening and sparsifying operator (SISSO) symbolic-regression approach. The notebook allows reproducing and modifying the analysis described in detail in:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "J. M. Mauß, K. Kley, R. Khobragade, N-K. Tran, J. De Bellis, F. Schüth, M. Scheffler, L. Foppa: <span style=\"font-style: italic;\">\"Modeling Time-On-Stream Catalyst Reactivity in the Selective Hydrogenation of Concentrated Acetylene Streams Under Industrial Conditions via Experiments and AI\"</span>, ChemRxiv,10.26434/chemrxiv-2025-vf7hd-v2 (2025) <a href=\"https://chemrxiv.org/engage/chemrxiv/article-details/67ea84986dde43c908d79032\" target=\"_blank\">[Paper]</a>.\n",
    "</div>\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "# Subgroup Discovery\n",
    "The SGD approach is based on a data set containing a target quantity of interest and many candidate descriptive parameters, whose values are known for all the samples in the data set. In the context of heterogeneous catalysis, the target quantity relates to the materials' function of interest (e.g., its activity) and the candidate descriptive parameters characterize the materials as well as the underlying processes that are potentially relevant for the considered function. \n",
    "From this data set, SGD generates of a pool of propositions, statements about the candidate descriptive parameters that apply only to a portion of the data set. For the case of continuous parameters, the propositions are inequalities describing constraints on the values of the descriptive parameters. Then, SGD identifies selectors, statements formed by a number of propositions combined via the “AND” connector (denoted “∧”), that result in the selection of subgroups of data points associated with the most outstanding distributions of the target values. The quality function $Q(SG,P)$ measures how outstanding a SG is. It has the form \n",
    "\n",
    "\\begin{equation}\n",
    " Q(SG,P) = \\frac{s(SG)}{s(P)}* u(SG,P)\n",
    "\\end{equation} \n",
    "\n",
    "where the first term, the coverage, contains the ratio between the number of data points in the subgroup, $s(SG)$, and the total number of data points in the whole data set, $s(P)$. This coverage term controls the subgroup size and prevents that very small SGs with little statistical significance are selected. The second term, $u(SG,P)$, is called utility function and it measures the dissimilarity between the SG and the whole data set, referred to as the population, $P$. \n",
    "\n",
    "The propositions entering the selectors resulting in the highest $Q(SG,P)$ values, and thus in the most outstanding SGs, can be seen as rules describing the exceptional SG behavior and reflecting the relevant underlying processes particularly related to the exceptional behavior. The parameters entering these propositions are, in turn, the key, most relevant, parameters associated with the outstanding SG performance, out of all the initially offered ones. Because the SG search is performed by maximizing a function measuring how outstanding specific subselections of data points are, this approach identifies a local behavior.\n",
    "\n",
    "The SGD approach is presented in further details in:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> B. R. Goldsmith, M. Boley, J. Vreeken, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">Uncovering structure-property relationships of materials by subgroup discovery.</span>, New J. Physics 19, 013031 (2017) <a href=\"https://doi.org/10.1088/1367-2630/aa57c2\" target=\"_blank\">[PDF]</a> .\n",
    "</div>\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> M. Boley, B. R. Goldsmith,  L. M. Ghiringhelli, J. Vreeken: <span style=\"font-style: italic;\">Identifying consistent statements about numerical data with dispersion-corrected subgroup discovery</span>, Data Min. Knowl. Discov. 31, 1391 (2017) <a href=\"https://doi.org/10.1007/s10618-017-0520-3\" target=\"_blank\">[PDF]</a> .\n",
    "</div>\n",
    "\n",
    "In this tutorial, we use the SGD algorithm as implemented in realkd, available in https://bitbucket.org/realKD/.\n",
    "\n",
    "\n",
    "# SISSO\n",
    "\n",
    "Symbolic regression is a possible avenue for linking physical reasoning and data-centric approaches when modelling materials properties and functions, since it identifies nonlinear analytical expressions relating a target property to key input parameters, out of many offered ones. These input parameters are typically physical quantities that are related to possible underlying processes governing the property. Because the key parameters can be directly identified by inspecting the analytical expressions, the models resulting from the SR analysis are interpretable. Another advantage of SR is that it can learn a representation for the property of interest based on data sets that are considered small (e.g., $10^2$ data points or less) in the context of widely used artificial-intelligence methods such as artificial neural networks. Thus, SR is particularly suited for materials science problems, in which consistent and well annotated data points might be scarce. Indeed, SR has been used to model several materials properties and functions in recent years.\n",
    "\n",
    "The SISSO approach starts with the collection of physical input parameters, candidate descriptive parameters or primary features. Then, a more expansive pool of expressions is iteratively built by exhaustively applying a set of mathematical operators to both the primary features and previously generated expressions. This step is referred to as the feature-creation step. The number of recursive applications of the operators used to construct the pool of expressions is called the rung (denoted $q$). Finally, compressed sensing is used to identify the best $D$-dimensional linear model by performing an $l_0$ regularization on a subspace $S$ of all generated expressions, where $S$ is selected using sure-independence screening. The Pearson correlation is used as the projection score. \n",
    "\n",
    "The outcome of the SISSO analysis is a low $D$-dimensional descriptor vector containing, as components, the expressions selected from the pool of expressions. A SISSO-derived model for a property $P$ has the form\n",
    "\n",
    "\\begin{equation}\n",
    " P^{\\mathrm{SISSO}} = \\sum_{i=0}^{D} c_i d_i\n",
    "\\end{equation} \n",
    "\n",
    "where $c_i$ are fitting coefficients and $d_i$ are the descriptor components. \n",
    "\n",
    "The SISSO algorithm is introduced in:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "R. Ouyang, S. Curtarolo, E. Ahmetcik, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">SISSO: a compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates</span>, Phys. Rev. Materials  2, 083802 (2018) <a href=\"https://journals.aps.org/prmaterials/abstract/10.1103/PhysRevMaterials.2.083802\" target=\"_blank\">[PDF]</a>.\n",
    "</div>\n",
    "\n",
    "# Focused AI Approach Combining SGD and SISSO\n",
    "\n",
    "The two-step focused AI modeling approach takes into account two different materials design criteria or targets, (i)  reactant conversion and (ii) selectivity. In the first step, subgroup discovery is applied to identify descriptions of subsets of materials and reaction conditions that exhibit noticeable conversion. In the second step, SISSO is used to model the selectivity for the subset of materials and conditions identified by SGD in the first step. Crucially, the selectivity will be modeled as a function of the time on stream, $t_{\\mathrm{OS}}$. We note that both SGD and SISSO are able to identify important primary features.  \n",
    "\n",
    "The outcome of the AI analysis is a SGD model that indicates whether a given material and reaction condition are associated with noticeable conversion. This classification is then subsequently quantified by a SISSO analysis which predicts the selectivity for the materials and reaction conditions that provide conversion. The SISSO models for selectivity do not attempt to describe all materials and reaction conditions simultaneously, but they focus on the situations of interest that were first identified by SGD. Therefore, in this focused AI approach, SGD identifies a description of a specific data space in which the SISSO model is trained.\n",
    "\n",
    "# Application: Modeling the Performance of Pd-Based Alloys Applied in the Selective Hydrogenation of Concentrated Acetylene Streams\n",
    "\n",
    "The focused AI approach will be demonstrated to model the measured time-on-stream-dependent reactivity of palladium-based bimetallic catalysts. These materials are synthesized via mechanochemistry and applied in the selective hydrogenation of concentrated acetylene streams under industrially relevant pressures, resulting from a hypothetical electric plasma-assisted methane-to-ethylene process. Unlike the well-established hydrogenation of diluted acetylene streams of naphtha steam cracking, the hydrogenation of concentrated acetylene streams remains largely underexplored due to the harsh reaction conditions and explosive nature of acetylene. This precludes operando characterization or atomistic simulations to investigate catalyst time-on-stream behavior under realistic conditions.\n",
    "\n",
    "The focused AI approach first uses SGD to identify descriptions of materials and reaction condition resulting in noticeable acetylene conversion. Then, it models time-dependent selectivity focused on high acetylene conversion via the SISSO symbolic-regression approach. AI identifies key experimental and theoretical physicochemical descriptive parameters correlated with the reactivity, which highlight the critical interplay between the materials structure and the chemical potential of the reaction. The AI models enable the design of bimetallic and trimetallic catalysts, which are experimentally validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from csv file\n",
    "df=pd.read_csv('./data/performance_data.csv')\n",
    "\n",
    "# The analysis focuses on the intial reaction times\n",
    "# Data points associated to nonphysical selectivity values are excluded\n",
    "df_initial=df.loc[(df['time (min)'] < 406)\n",
    "                 & (df['S_ethane'] > -0.1)\n",
    "                 & (df['S_ethane'] < 2.1)\n",
    "                 & (df['S_ethylene'] < 1)\n",
    "                 & (df['S_ethylene'] > -1.2)]\n",
    "\n",
    "# The dataset contains 12 materials measured at three temperatures (50, 100, and 150 C) \n",
    "# and multiple times on stream. In total, there are 1076 data points.\n",
    "print(len(df_initial))\n",
    "df_initial.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Taget Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analysis focuses on the performance metrics acetylene conversion\n",
    "# ethylene selectivity, ethane selectivity, and C4 selectivity\n",
    "performance_targets =['X_acetylene',\n",
    "                     'S_ethylene',\n",
    "                     'S_ethane',\n",
    "                     'S_C4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The acetyelene conversion and ethylene selectivity are plotted in the following figure\n",
    "# Define catalyst names and captions\n",
    "catalyst_list = [f'PdAg_1_{i}' for i in [9, 5, 1]] + \\\n",
    "                [f'PdAu_1_{i}' for i in [9, 5, 1]] + \\\n",
    "                [f'PdCu_1_{i}' for i in [9, 5, 1]] + ['Ag', 'Au', 'Cu']\n",
    "\n",
    "catalyst_list_caption = [r'Pd$_1$Ag$_9$', r'Pd$_1$Ag$_5$', r'Pd$_1$Ag$_1$',\n",
    "                         r'Pd$_1$Au$_9$', r'Pd$_1$Au$_5$', r'Pd$_1$Au$_1$',\n",
    "                         r'Pd$_1$Cu$_9$', r'Pd$_1$Cu$_5$', r'Pd$_1$Cu$_1$',\n",
    "                         'Ag', 'Au', 'Cu']\n",
    "\n",
    "# Predefine temperatures and storage containers\n",
    "temperatures = [50, 100, 150]\n",
    "sel_matrices, act_matrices, masks = {}, {}, {}\n",
    "\n",
    "# Extract data for each catalyst and temperature\n",
    "for T in temperatures:\n",
    "    sel_matrices[T], act_matrices[T] = [], []\n",
    "    for cat in catalyst_list:\n",
    "        data = df_initial[df_initial['material_Temperature'] == f\"{cat}_{T}\"]\n",
    "        sel = list(data['S_ethylene'].iloc[::3])\n",
    "        act = list(data['X_acetylene'].iloc[::3])\n",
    "        sel_matrices[T].append(sel)\n",
    "        act_matrices[T].append(act)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    sel_np = np.array(sel_matrices[T])\n",
    "    act_np = np.array(act_matrices[T])\n",
    "    \n",
    "    # Mask values where conversion is below 99%\n",
    "    masks[T] = np.ma.masked_where(act_np <= 0.99, sel_np)\n",
    "\n",
    "# Plotting \n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "# Shared colormap\n",
    "cmap = cm.get_cmap('viridis').copy()\n",
    "cmap.set_bad(color='lightgrey')\n",
    "\n",
    "# Shared x-ticks from any dataset\n",
    "x_ticks = list(df_initial[df_initial['material_Temperature'] == f\"{catalyst_list[0]}_{temperatures[0]}\"]['time (min)'].iloc[::3])\n",
    "\n",
    "# Create subplots for each temperature\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(masks[T], cmap=cmap, vmin=-1, vmax=0.75)\n",
    "\n",
    "    # Axis labels and ticks\n",
    "    ax.set_xlabel(r'$t_{\\mathrm{OS}}$ (min)')\n",
    "    ax.set_xticks(range(len(x_ticks)))\n",
    "    ax.set_xticklabels(x_ticks, rotation=90)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.set_yticks(range(len(catalyst_list_caption)))\n",
    "        ax.set_yticklabels(catalyst_list_caption)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Horizontal lines to separate metal groups\n",
    "    for y in range(3, masks[T].shape[0], 3):\n",
    "        ax.axhline(y - 0.5, color='white', linestyle='--', linewidth=1.8)\n",
    "\n",
    "    ax.set_title(fr'$T_{{\\mathrm{{oven}}}}={T} \\degree$ C')\n",
    "\n",
    "# Shared colorbar\n",
    "fig.colorbar(im, ax=axes, shrink=0.475, label=r'$S_{\\mathrm{C_2H_4}}$ at $X_{\\mathrm{C_2H_2}} \\geq 0.99$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Candidate Descriptive Parameters (Primary Features)\n",
    "\n",
    "As candidate descriptive parameters (primary features) characterizing the materials and reaction conditions, we collected four parameters from the experimental characterization of the materials by energy dispersive X-ray analysis in a scanning electron microscope (EDX-SEM), high-resolution transmission-electron microscopy (TEM), and N$_2$ physisorption, such as the mean particle diameter ($D_\\mu$) and the specific surface area ($s_{\\mathrm{BET}}$).\n",
    "Additionally, we included three experimental elemental (free-atom) properties and three experimental bulk properties as parameters reflecting the chemistry of the bulk of the metal NPs, such as the ionization potential ($IP$) and the closest interatomic distance ($d_{\\mathrm{closest}}$). Finally, we utilized nine parameters reflecting the properties of the surfaces of the metal NPs and the interaction of carbon and hydrogen with the surface and subsurface. These parameters were calculated by density functional theory under the generalized gradient approximation (DFT-GGA) on low-index model surfaces. Examples of such parameters are the energy of the $d$-band center($\\epsilon_d$),\\cite{Hammer-2000}, and the binding energy of subsurface hydrogen and carbon ($E_{\\mathrm{b,H}}^{\\mathrm{sub}}$ and $E_{\\mathrm{b,C}}^{\\mathrm{sub}}$, respectively). The elemental, bulk, and surface-related properties were converted into materials-specific parameters by taking the composition average, indicated by the bar in $\\overline{\\phi}$, where $\\phi$ is an elemental, bulk, or surface parameter. Finally, $t_{\\mathrm{OS}}$ and $T_{\\mathrm{oven}}$ were used as parameters related to the applied reaction conditions. \n",
    "In total, 21 candidate descriptive parameters were collected (see full list in Table S1 as well details on the experimental or theoretical methods used to obtain them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect the values of the candidate descriptive parameters \n",
    "# plot the distribution of their values, and analyze the correlations between them\n",
    "\n",
    "reaction_parameters=['time (min)','T_reactor (C)']\n",
    "\n",
    "materials_parameters=['total_metal_loading', \n",
    "                      'particle_diameter (nm)',\n",
    "                      'std_dev (nm)', \n",
    "                      'surface_area (m^2/g)',\n",
    "                      'av_IP (eV)', \n",
    "                      'av_EA (eV)', \n",
    "                      'av_PE',\n",
    "                      'av_bulk_int_dist (A)', \n",
    "                      'av_E_coh (eV/atom)', \n",
    "                      'av_B_0 (Gpa)', \n",
    "                      'av_mu_C_critical_surf (eV)',\n",
    "                      'av_mu_C_critical_subsurf (eV)', \n",
    "                      'av_E_b_C_subsurf (eV)', \n",
    "                      'av_E_def_subsurf (eV)',\n",
    "                      'av_delta_M1_M2_subsurf', \n",
    "                      'av_BE_H_surf (eV)', \n",
    "                      'av_W_change_H (eV)',\n",
    "                      'av_d_band_center_surf (eV)', \n",
    "                      'av_BE_H_subsurf (eV)']\n",
    "\n",
    "materials_parameters_labels=[r'$w_{\\mathrm{metal}}$' , \n",
    "                             r'$D_\\mu$', \n",
    "                             r'$D_\\sigma$',\n",
    "                             r'$s_{\\mathrm{BET}}$', \n",
    "                             r'$\\overline{IP}$', \n",
    "                             r'$\\overline{EA}$', \n",
    "                             r'$\\overline{EN}$',\n",
    "                             r'$\\overline{d_{\\mathrm{closest}}}$', \n",
    "                             r'$\\overline{E_{\\mathrm{coh}}}$', \n",
    "                             r'$\\overline{B_{\\mathrm{0}}}$',\n",
    "                             r'$\\overline{\\mu_{\\mathrm{C}}^{\\mathrm{surf}}}$',\n",
    "                             r'$\\overline{\\mu_{\\mathrm{C}}^{\\mathrm{sub}}}$',\n",
    "                             r'$\\overline{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$', \n",
    "                             r'$\\overline{E_{\\mathrm{d,C}}^{\\mathrm{sub}}}$',\n",
    "                             r'$\\overline{\\delta_{\\mathrm{C}}^{\\mathrm{sub}}}$', \n",
    "                             r'$\\overline{E_{\\mathrm{b,H}}^{\\mathrm{surf}}}$', \n",
    "                             r'$\\overline{\\Delta W_{\\mathrm{H}}^{\\mathrm{surf}}}$',\n",
    "                             r'$\\overline{\\epsilon_d}$',\n",
    "                             r'$\\overline{E_{\\mathrm{b,H}}^{\\mathrm{sub}}}$']\n",
    "\n",
    "features=reaction_parameters+materials_parameters\n",
    "\n",
    "df_materials_parameters = df_initial[materials_parameters].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram grid\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over each parameter and its label\n",
    "for i, (param, label) in enumerate(zip(materials_parameters, materials_parameters_labels)):\n",
    "    ax = axes[i]\n",
    "    ax.hist(df_materials_parameters[param], bins=20, color='k')\n",
    "    ax.set_title(label)\n",
    "    #ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(len(materials_parameters), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Distribution of Material Parameters', fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "fig,ax1 = plt.subplots(1,1, constrained_layout=True, figsize=(5,5))\n",
    "\n",
    "\n",
    "matrix = np.triu(df_materials_parameters)\n",
    "pearson_correlation = df_materials_parameters.corr(method='pearson')\n",
    "sns.heatmap(pearson_correlation, \n",
    "            xticklabels=materials_parameters_labels,\n",
    "            yticklabels=materials_parameters_labels,\n",
    "            cmap='RdBu_r',\n",
    "            annot=False,\n",
    "            linewidth=0.5,\n",
    "            vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: SGD Identification of Descriptions of Materials and Reaction Conditions Resulting in Noticeable Acetylene Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify columns to extract (index, target, and features to be used in SGD)\n",
    "columns_to_extract =['material_Temperature','material_Temperature_time']+performance_targets+features\n",
    "\n",
    "# Extract the specified columns\n",
    "df_SGD = df_initial[columns_to_extract].copy().set_index('material_Temperature_time')\n",
    "\n",
    "# Rename columns by removing the units (in parentheses)\n",
    "df_SGD.columns = [re.sub(r'\\s*\\(.*?\\)', '', col).strip() for col in df_SGD.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input files for SGD\n",
    "def write_input_SGD(path, df, id_job, n_cutoffs, algo, dev, n_res, n_seeds, target_key, weight):\n",
    "    \"\"\"\n",
    "    creates the two input files necessary to run SGD with realkd:\n",
    "    i) a .json file with calculation details, named \"id_job.json\", and\n",
    "    ii) a .xarf file with the data set, named \"id_job.xarf\".\n",
    "    function arguments: path(str): path to the folder where the files \n",
    "                                   will be written\n",
    "               df(data frame): data set containing the values for the \n",
    "                               candidate descriptive parameters and for\n",
    "                               the target for all materials\n",
    "               id_job(str): job name\n",
    "               n_cutoffs(int): number of cutoffs to be used in k-Means\n",
    "                               clustering to generate the propositions\n",
    "               algo(str): SG search algorithm:\n",
    "                          PMM_SAMPLER \n",
    "                          EMM_SAMPLER\n",
    "                          EXCEPTIONAL_SUBGROUP_BESTFIRST_BRANCHANDBOUND\n",
    "                          \n",
    "                          PMM_SAMPLER uses (std(SG)-std(P))/std(P) as utility function\n",
    "                          whereas EMM_SAMPLER/EXCEPTIONAL_SUBGROUP_BESTFIRST_BRANCHANDBOUND \n",
    "                          use the function specified in dev\n",
    "               \n",
    "               dev(str): deviation measure when using EMM_SAMPLER: \n",
    "                         cumulative_jensen_shannon_divergence\n",
    "                         normalized_positive_mean_shift\n",
    "                         normalized_negative_mean_shift\n",
    "                         normalized_positive_median_shift\n",
    "                         normalized_negative_median_shift\n",
    "                         \n",
    "               n_res(int): number of results, i.e., number of top-ranked\n",
    "                           SGs to display\n",
    "               n_seeds(int): number of seeds to use for the SG search\n",
    "               target_key(str): label of the variable to be used as target quantity in SGD\n",
    "    \"\"\"\n",
    "    df.to_csv(path+'/'+id_job+'.csv')\n",
    "    with open(path+'/'+id_job+'.csv', 'r') as file_in:\n",
    "        data = file_in.read().splitlines(True)\n",
    "        \n",
    "    file_out = open(path+'/'+id_job+'.xarf', 'w')\n",
    "    file_out.write('@relation '+id_job+'\\n')\n",
    "    file_out.write('@attribute materials name\\n')\n",
    "    for variable in list(df.columns):\n",
    "        file_out.write('@attribute '+variable+' numeric\\n')\n",
    "    file_out.write(\"@data\\n\")\n",
    "    file_out.close()\n",
    "\n",
    "    with open(path+'/'+id_job+'.xarf', 'a') as file_out:\n",
    "        file_out.writelines(data[1:])\n",
    "        file_out.close()\n",
    "    \n",
    "    input_file = {}\n",
    "    input_file = {\"type\" : \"productWorkScheme\",\n",
    "                  \"id\" : id_job,\n",
    "                  \"workspaces\" : [ {\n",
    "                                \"type\" : \"workspaceFromXarf\",\n",
    "                                \"id\" : id_job,\n",
    "                                \"datafile\" : id_job+\".xarf\",\n",
    "                                \"propScheme\": {\"type\": \"standardPropScheme\",\n",
    "                                                \"defaultMetricRule\": {\"type\": \"kmeansPropRule\",\n",
    "                                                                       \"numberOfCutoffs\": n_cutoffs,\n",
    "                                                                       \"maxNumberOfIterations\": 1000}}} ],\n",
    "                    \"computations\" : [ {\n",
    "                                \"type\" : \"legacyComputation\",\n",
    "                                \"id\" : \"subgroup_analysis\",\n",
    "                                \"algorithm\" : algo,\n",
    "                                \"parameters\" : {\n",
    "                                    \"dev_measure\": dev,\n",
    "                                    \"attr_filter\" : \"[]\",\n",
    "                                    \"cov_weight\" : weight,\n",
    "                                    \"num_res\" : n_res,\n",
    "                                    \"num_seeds\" : n_seeds,\n",
    "                                    \"targets\" : \"[\"+target_key+\"]\"\n",
    "                                             }\n",
    "                  }],\n",
    "                  \"computationTimeLimit\" : 3600000\n",
    "                     }\n",
    "    with open(path+'/'+id_job+'.json','w') as outfile:\n",
    "        json.dump(input_file, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the SGD job\n",
    "job_id='SGD_test_job_name'\n",
    "\n",
    "# Speficy SGD parameters\n",
    "# Number of thresholds (k in k-means clustering)\n",
    "n_clusters=20\n",
    "\n",
    "#Number of seeds used to initialize the SGD search algorithm (opportunistic pruning)\n",
    "n_seeds=50000\n",
    "\n",
    "#Number of SGD solutions to be printed\n",
    "n_results=5000\n",
    "\n",
    "#Check if old files exist for the specified job_id and remove them\n",
    "dirpath = os.path.join('./output/', job_id)\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "# Write input files\n",
    "# The utility function \"standard deviation reduction\" is chosen (\"PMM_SAMPLER\")\n",
    "write_input_SGD('./', \n",
    "            df_SGD.drop(['material_Temperature', 'time', 'S_ethylene', 'S_ethane','S_C4'], axis=1), \n",
    "            job_id, \n",
    "            n_clusters,\n",
    "            'PMM_SAMPLER',\n",
    "            '',\n",
    "            n_results, \n",
    "            n_seeds,\n",
    "            columns_to_extract[2],\n",
    "            1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate conda environment to load java \n",
    "# And run SGD\n",
    "\n",
    "!source $CONDA_PREFIX/bin/activate base && conda activate T8 && java -jar realkd-0.7.2-jar-with-dependencies.jar '{job_id}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze the results of SGD\n",
    "def analyze_output_SGD(file_results):\n",
    "    \n",
    "    list_coverages=[]\n",
    "    list_utility_function=[]\n",
    "    list_quality_function=[]\n",
    "    list_target_mean=[]\n",
    "    list_constraints=[]\n",
    "    \n",
    "    with open(file_results) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for index in range(len(data)):\n",
    "            coverage=data[index].get('measurements')[0].get('value')\n",
    "            utility_function=data[index].get('measurements')[1].get('value')\n",
    "            quality_function=coverage*utility_function\n",
    "            target_mean=data[index].get('descriptor').get('targetLocalModel').get('means')\n",
    "            list_attributes=data[index].get('descriptor').get('selector').get('attributes')\n",
    "            list_operators=[]\n",
    "            list_cutoffs=[]\n",
    "            constraints=[]\n",
    "            for i in list(range(0,len(list_attributes))):\n",
    "                list_operators.append(data[index].get('descriptor').get('selector').get('constraints')[i].get('type'))\n",
    "                list_cutoffs.append(round(data[index].get('descriptor').get('selector').get('constraints')[i].get('value'),4))\n",
    "\n",
    "            list_operators = [op.replace('lessOrEquals', '<=') for op in list_operators]\n",
    "            list_operators = [op.replace('greaterOrEquals', '>=') for op in list_operators]\n",
    "            list_operators = [op.replace('lessThan', '<') for op in list_operators]\n",
    "            list_operators = [op.replace('greaterThan', '>') for op in list_operators]\n",
    "    \n",
    "            for i in list(range(0,len(list_attributes))):\n",
    "                if i == 0:\n",
    "                    constraints=list_attributes[0]+list_operators[0]+str(list_cutoffs[0])\n",
    "                else:\n",
    "                    constraints=constraints+' & '+list_attributes[i]+list_operators[i]+str(list_cutoffs[i])\n",
    "            list_coverages.append(coverage)\n",
    "            list_utility_function.append(utility_function)\n",
    "            list_quality_function.append(quality_function)\n",
    "            list_target_mean.append(*target_mean)\n",
    "            list_constraints.append(constraints)\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(list(zip(list_coverages,\n",
    "                               list_utility_function,\n",
    "                               list_quality_function,\n",
    "                              list_target_mean,\n",
    "                               list_constraints)), \n",
    "                      columns =['coverage','utility','quality','target_mean','constraints'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze the results obtained in the publication, uncomment the following line\n",
    "job_id='SGD_results_publication'\n",
    "\n",
    "# Path to the file with the SGD results\n",
    "file_results='./output/'+job_id+'/'+os.listdir('./output/'+job_id+'/')[0]+'/results/'+job_id+'_subgroup_analysis.json'\n",
    "\n",
    "# The results are stored in a dataframe that shows a list of SGs ranked by their quality-function values \n",
    "df_SGD_results=analyze_output_SGD(file_results)\n",
    "df_SGD_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the rules associated to the SG presenting the highest value of quality function\n",
    "df_SGD_results.iloc[0]['constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of target performance metrics in the entire dataset\n",
    "# and in the identified SG\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, constrained_layout=True, figsize=(6,6))\n",
    "\n",
    "# Apply the SG rules (constraints) to the dataset\n",
    "df_SGD_selected=df_SGD.query(df_SGD_results['constraints'][0])\n",
    "\n",
    "color_entire_dataset='black'\n",
    "color_SG='red'\n",
    "n_bins=20\n",
    "\n",
    "ax1.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax1.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "axins = inset_axes(ax1, width=\"65%\", height=\"35%\",loc=2)\n",
    "axins.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "axins.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "axins.set_ylim(0,40)\n",
    "\n",
    "ax2.hist(df_initial['S_ethylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax2.hist(df_SGD_selected['S_ethylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax3.hist(df_initial['S_ethane'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax3.hist(df_SGD_selected['S_ethane'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax4.hist(df_initial['S_C4'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax4.hist(df_SGD_selected['S_C4'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax1.set_ylabel('Counts')\n",
    "ax2.set_ylabel('Counts')\n",
    "ax3.set_ylabel('Counts')\n",
    "ax4.set_ylabel('Counts')\n",
    "\n",
    "ax1.set_xlabel('$X_{\\mathrm{acetylene}}$')\n",
    "ax2.set_xlabel('$S_{\\mathrm{ethylene}}$')\n",
    "ax3.set_xlabel('$S_{\\mathrm{ethane}}$')\n",
    "ax4.set_xlabel('$S_{\\mathrm{C4}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the SG identified in the publication,\n",
    "# we plot the 12 materials in the coordinates of the two materials-related parameters appearing in the rules\n",
    "fig, (ax1) = plt.subplots(1,1, constrained_layout=True, figsize=(4,4))\n",
    "marker_size=30\n",
    "ax1.vlines(4.6685,2.5659,3.05,color='red',linestyle='dashed')\n",
    "ax1.hlines(2.5659,4.6685,9,color='red',linestyle='dashed')\n",
    "ax1.fill_between([4.6685,9], 2.5659, 3.05, color='mistyrose')\n",
    "\n",
    "ax1.scatter(df_SGD['av_E_b_C_subsurf'],df_SGD['av_bulk_int_dist'],c=color_entire_dataset,s=marker_size)\n",
    "ax1.scatter(df_SGD_selected['av_E_b_C_subsurf'],df_SGD_selected['av_bulk_int_dist'],c=color_SG,s=marker_size)\n",
    "\n",
    "ax1.set_ylim(2.5,3.05)\n",
    "ax1.set_xlim(4,7.25)\n",
    "ax1.arrow(4.6685, 2.7, 0.5, 0, head_width=0.015, head_length=0.2, color=color_SG)\n",
    "ax1.arrow(5.8, 2.5659, 0, 0.06, head_width=0.10, head_length=0.03, color=color_SG)\n",
    "\n",
    "ax1.set_xlabel('$\\\\widebar{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$ (eV)')  \n",
    "ax1.set_ylabel('$\\\\widebar{d_{\\mathrm{closest}}}$ ($\\mathrm{\\AA}$)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training SISSO Models for Selectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first visualize the selectivity values as a function of time on stream for the datapoints selected in the SG\n",
    "\n",
    "# Configure global plot font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Create grid of subplots (for three products at two temperatures)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "# Define visual properties for catalysts \n",
    "colors = ['grey'] * 3 + ['darkorange'] * 3 + ['brown'] * 3\n",
    "markers = ['s', '>', 'o'] * 3\n",
    "marker_size = 30\n",
    "\n",
    "# Loop over each of the 9 catalysts\n",
    "for i in range(9):    \n",
    "    # Get time-series data for current catalyst at 100°C and 150°C\n",
    "    cat_100 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_100']\n",
    "    cat_150 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_150']\n",
    "    \n",
    "    # Scatter plot for S_ethylene\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    \n",
    "    # Scatter plot for S_ethane\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    \n",
    "    # Scatter plot for S_C4\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "\n",
    "# Set axes limits\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.set_xlim(0, 406)\n",
    "ax1.set_ylim(-1.1, 1.5)\n",
    "ax2.set_ylim(-1.1, 1.5)\n",
    "ax3.set_ylim(0, 2.1)\n",
    "ax4.set_ylim(0, 2.1)\n",
    "ax5.set_ylim(0, 0.2)\n",
    "ax6.set_ylim(0, 0.2)\n",
    "\n",
    "# Set axis labels\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax3.set_ylabel('$S_{\\mathrm{C_2H_6}}$')\n",
    "ax5.set_ylabel('$S_{\\mathrm{C4}}$')\n",
    "ax5.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "ax6.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "\n",
    "# Tweak tick labels visibility for cleaner layout\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in [ax2, ax4, ax6]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Add subplot titles for temperature conditions\n",
    "ax1.set_title('$T_{\\mathrm{oven}} = 100\\,^\\circ\\mathrm{C}$')\n",
    "ax2.set_title('$T_{\\mathrm{oven}} = 150\\,^\\circ\\mathrm{C}$')\n",
    "\n",
    "# Add horizontal reference line at y=0 to the top row\n",
    "ax1.axhline(0, color='k', linewidth=0.5)\n",
    "ax2.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Add legend for catalysts (only once)\n",
    "ax2.legend(\n",
    "    labels=catalyst_list_caption[:9],\n",
    "    loc=(1.04, 0.05),\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    "    fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataset with the training data for SISSO is created based on the SG rules identified in the publication\n",
    "# It contains 539 data points, ca. 50% of the original dataset \n",
    "df_SISSO=df_initial.loc[(df_initial['T_reactor (C)'] > 75)\n",
    "                      & (df_initial['av_bulk_int_dist (A)'] >=2.5659)\n",
    "                      & (df_initial['av_E_b_C_subsurf (eV)'] >= 4.6685)]\n",
    "len(df_SISSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nested 5-fold strategy is used in order to evaluate the performance of the SISSO models. The outer loop is used to evaluate prediction (or test) errors, whereas the inner loop is used for evaluating the optimal model hyperparameters. In the context of SISSO, two parameters control the model complexity, the rung $q$ and the model dimensionality $D$. The optimal set of hyperparameters is considered the one providing the lowest validation errors. In particular, we use the root mean squared error averaged over the five validation sets as our performance metric. In this work, we consider $q=1,2$ and $D=1,2,3,4,5$. Further details can be found in the Supplemental Material <a href=\"https://journals.aps.org/prl/supplemental/10.1103/PhysRevLett.129.055301/ESI.pdf\" target=\"_blank\">[PDF]</a> of the publication.  \n",
    "\n",
    "<img style=\"float: center;\" src=\"data/nested_CV.png\" width=650>\n",
    "\n",
    "The sample indices correspoding to the nested 5-fold procedure are obtained as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_out=KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "\n",
    "indices_train_out=[]\n",
    "indices_test=[]\n",
    "\n",
    "for train_index,test_index in kf_out.split(df_SISSO):\n",
    "    indices_train_out.append(train_index)\n",
    "    indices_test.append(test_index)\n",
    "\n",
    "kf_in=KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "\n",
    "indices_train_in=[]\n",
    "indices_validation=[]\n",
    "\n",
    "for train_index,test_index in kf_in.split(df_SISSO.iloc[indices_train_out[0],:]):\n",
    "    indices_train_in.append(train_index)\n",
    "    indices_validation.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input files for SISSO\n",
    "def write_input_SISSO(train,rung,dim,n_sis,n_res,ops,leave_out_ind,path,calculation_type):\n",
    "    \"\"\"Creates the directory and writes the input files (sisso.json and train.dat) for SISSO++\n",
    "    \n",
    "    Args:\n",
    "        train (pd.DataFrame): dataframe containing the data set\n",
    "        rung (int): number of iterations for operator application (e.g. 1, 2 or 3)\n",
    "        dim (int): descriptor dimension\n",
    "        n_sis (int): size of the SIS-selected feature spaces\n",
    "        n_res (int): number of residuals\n",
    "        ops (list): list of mathematical operators (str)\n",
    "        leave_out_ind (list): index of the materials to be left out from training, i.e., test materials\n",
    "        path (str): path of the directory to be created \n",
    "        calculation_type (str): type of calculation (e.g., regression or log_regression)\n",
    "    \"\"\"\n",
    "    rung_store = max(0, rung - 1)\n",
    "    rung_gen = 0 if rung < 3 else 1\n",
    "        \n",
    "    os.mkdir(path)\n",
    "    train.to_csv(f\"{path}/train.dat\")\n",
    "    prop_key=train.columns.values[0].split()[0]\n",
    "    input_file = {\n",
    "        'desc_dim':dim,\n",
    "        'n_sis_select':n_sis,\n",
    "        'max_rung':rung,\n",
    "        'n_rung_store':rung_store,\n",
    "        'n_residual':n_res,\n",
    "        'min_abs_feat_val': 1e-6,\n",
    "        'max_abs_feat_val': 1e6,\n",
    "        'data_file': 'train.dat',\n",
    "        'property_key': prop_key,\n",
    "        'n_rung_generate': rung_gen,\n",
    "        'leave_out_inds': leave_out_ind,\n",
    "        'n_models_store': 10,\n",
    "        'opset': ops, \n",
    "        \"param_opset\": [\n",
    "        \"exp\",\n",
    "        \"log\"], \n",
    "        'global_param_opt': 'True',\n",
    "        'calc_type': calculation_type,\n",
    "    }\n",
    "    with open(f\"{path}/sisso.json\",'w') as outfile:\n",
    "        json.dump(input_file, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speficy SISSO parameters\n",
    "\n",
    "# Set of operators utilized to create the analytical expressions\n",
    "operator_set = [\"add\", \n",
    "                \"sub\", \n",
    "                \"abs_diff\", \n",
    "                \"mult\", \n",
    "                \"div\", \n",
    "                \"inv\", \n",
    "                \"exp\", \n",
    "                \"sq\", \n",
    "                \"cb\", \n",
    "                \"sqrt\", \n",
    "                \"cbrt\", \n",
    "                \"log\", \n",
    "                \"abs\", \n",
    "                \"six_pow\",\n",
    "                \"neg_exp\"] \n",
    "\n",
    "# Number of residuals\n",
    "n_res=5\n",
    "\n",
    "#Number of model dimensions\n",
    "dimension=5\n",
    "\n",
    "#Size of subspaces of features selected by SIS\n",
    "n_sis=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create directories and write SISSO input files associated to the nested cross-validation scheme\n",
    "# We also train SISSO models utilizing the entire dataset of 539 data points \n",
    "\n",
    "os.mkdir('./output/full_dataset')\n",
    "for fold in [0,1,2,3,4]:\n",
    "    os.mkdir('./output/fold_'+str(fold))\n",
    "        \n",
    "for target in performance_targets[1:]:\n",
    "    for rung in [1,2]:\n",
    "        df_SISSO_outer_loop=df_SISSO[['material_Temperature']+[target]+['task']+features].copy().set_index('material_Temperature')\n",
    "        write_input_SISSO(df_SISSO_outer_loop,\n",
    "                        rung, dimension, n_sis, n_res, operator_set,\n",
    "                        '[]',\n",
    "                        './output/full_dataset/'+target+'_r'+str(rung),\n",
    "                       'regression')\n",
    "        for fold in [0,1,2,3,4]:\n",
    "            write_input_SISSO(df_SISSO_outer_loop,\n",
    "                        rung, dimension, n_sis, n_res, operator_set,\n",
    "                        indices_test[fold].tolist(),\n",
    "                        './output/fold_'+str(fold)+'/'+target+'_r'+str(rung),\n",
    "                       'regression')\n",
    "            \n",
    "            os.mkdir('./output/fold_'+str(fold)+'/'+target+'_r'+str(rung)+'_cv')\n",
    "            for it in [0,1,2,3,4]:\n",
    "                    write_input_SISSO(df_SISSO_outer_loop.iloc[indices_train_out[fold],:],\n",
    "                                rung, dimension, n_sis, n_res, operator_set,\n",
    "                                 indices_validation[it].tolist(),\n",
    "                                 './output/fold_'+str(fold)+'/'+target+'_r'+str(rung)+'_cv/iter_'+str(it),\n",
    "                                'regression')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain the validation errors of SISSO models\n",
    "def get_rmse_vs_dim(path,path_cv,n_iter,dim,unit_length):\n",
    "    \"\"\"\n",
    "    reads SISSO++ output (sisso.out) and returns train and validation errors as a function of descriptor dimension\n",
    "    arguments: path(str): directory containing the output files obtained with the outer-loop data set splits\n",
    "               path_cv(str): directory containing the output files obtained with the inner-loop data set splits (cross-validation)\n",
    "               n_iter(int): number of CV iterations\n",
    "               dim(int): descriptor max dimension\n",
    "               unit_length(int): lenght of the property unit\n",
    "    \"\"\"\n",
    "    train_errors=[]\n",
    "    cv_errors=[]\n",
    "    avg_cv_errors=[]\n",
    "    std_cv_errors=[]\n",
    "    with open(path+'/sisso.out') as f:\n",
    "        data = f.readlines()\n",
    "        i = 0\n",
    "        for line in data:\n",
    "            if line.__contains__('Train'):\n",
    "                train_rmse =float(line.split()[2].split(';')[0])\n",
    "                train_errors.append(train_rmse)\n",
    "                i += 1\n",
    "    \n",
    "    for it in [*range(n_iter)]:\n",
    "        with open(path_cv+'/iter_'+str(it)+'/sisso.out') as f:\n",
    "            data = f.readlines()\n",
    "            i = 0\n",
    "            for line in data:\n",
    "                if line.__contains__('Train'):\n",
    "                    test_rmse = float(line.split()[6+(unit_length-1)])\n",
    "                    cv_errors.append([i, test_rmse])\n",
    "                    i += 1\n",
    "    for d in [*range(dim)]:\n",
    "        a=[]\n",
    "        for k in [*range(len(cv_errors))]:\n",
    "            if cv_errors[k][0] == d:\n",
    "                a.append(cv_errors[k][1])\n",
    "        avg_cv_errors.append(np.average(a))\n",
    "        std_cv_errors.append(np.std(a))\n",
    "                \n",
    "    return(train_errors, avg_cv_errors, std_cv_errors) \n",
    "\n",
    "# Function to obtain the predictions of SISSO models on the test sets\n",
    "def get_test_data(path,n_iter,rung,dim,prop):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_data=pd.DataFrame()\n",
    "    for it in [*range(n_iter)]:\n",
    "        d=pd.read_csv(path+'fold_'+str(it)+'/'+str(prop)+'_r'+str(rung)+'/models/test_dim_'+str(dim)+'_model_0.dat', comment='#', header=None)\n",
    "        test_data=pd.concat([test_data,d])\n",
    "    return(test_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the validation errors utilizing the output files provided in ./output/SISSO_results_publication\n",
    "\n",
    "# Set default font size for plots\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# X-axis values and style definitions\n",
    "x = [1, 2, 3, 4, 5]\n",
    "colors = ['', 'red', 'blue']  # rung 1: red, rung 2: blue\n",
    "labels = ['', '$q=1$', '$q=2$']\n",
    "\n",
    "# Loop through each performance target\n",
    "for target in performance_targets[1:]:\n",
    "    # Define y-axis upper limit as a fraction of the target's std deviation\n",
    "    std_of_target = np.std(df_SISSO[target]) * 0.6\n",
    "\n",
    "    # Create 1 row x 5 columns subplot grid, one per data fold\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 4), constrained_layout=True)\n",
    "\n",
    "    for fold, ax in enumerate(axes):\n",
    "        # Plot results for each rung (model complexity level)\n",
    "        for rung in [1, 2]:\n",
    "            # Build file path and load RMSE values\n",
    "            path = f'./output/SISSO_results_publication/fold_{fold}/{target}_r{rung}'\n",
    "            errors = get_rmse_vs_dim(path, path + '_cv', 5, 5, 1)\n",
    "\n",
    "            # Plot with error bars\n",
    "            ax.errorbar(x, errors[1], yerr=errors[2],\n",
    "                        color=colors[rung],\n",
    "                        marker='o',\n",
    "                        mfc=colors[rung],\n",
    "                        capsize=4,\n",
    "                        label=labels[rung])\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_xlim(0.5, 5.5)\n",
    "        ax.set_xticks([1, 2, 3, 4, 5])\n",
    "        ax.set_xlabel('$D$')  # D = descriptor dimension\n",
    "\n",
    "        # Y-axis settings\n",
    "        ax.set_ylim(0, std_of_target)\n",
    "        if fold == 0:\n",
    "            ax.set_ylabel('Cross-validation RMSE')\n",
    "        else:\n",
    "            ax.set_yticks([])  # Remove y-ticks from all but the first plot\n",
    "\n",
    "        # Add second Y-axis\n",
    "        ax_twin = ax.twinx()\n",
    "        ax_twin.set_ylim(0, 60)\n",
    "        ax_twin.set_yticks([])\n",
    "        if fold == 4:\n",
    "            ax_twin.set_ylabel('Cross-validation RMSE / $\\sigma$ (%)')\n",
    "\n",
    "        # Add legend only in the first plot\n",
    "        if fold == 0:\n",
    "            ax.legend(loc='upper right', frameon=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test errors utilizing the output files provided in ./output/SISSO_results_publication\n",
    "\n",
    "# Plot style settings\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Optimal rung and descriptor dimension for each target, as identified based on the validation errors (above)\n",
    "optimal_rungs = [2, 2, 2]\n",
    "optimal_dimensions = [3, 3, 3]\n",
    "\n",
    "# Plot customization for boxplots and violin plots\n",
    "colors = ['lightblue']\n",
    "boxprops = {\"zorder\": 100, \"linewidth\": 1.5, \"edgecolor\": \"k\", \"facecolor\": \"none\"}\n",
    "whiskerprops = {\"zorder\": 100, \"color\": \"k\", \"linewidth\": 1.5}\n",
    "capprops = {\"zorder\": 100, \"color\": \"k\", \"linewidth\": 1.5}\n",
    "medianprops = {\"linewidth\": 1.5, \"color\": \"orange\", \"zorder\": 200}\n",
    "meanprops = {\n",
    "    \"marker\": \"x\", \"markersize\": 10.0,\n",
    "    \"markerfacecolor\": \"k\", \"markeredgecolor\": \"k\",\n",
    "    \"zorder\": 500\n",
    "}\n",
    "\n",
    "# Descriptor labels for each subplot\n",
    "xlabels = ['$S_{\\mathrm{C_2H_4}}$', '$S_{\\mathrm{C_2H_6}}$', '$S_{\\mathrm{C_4}}$']\n",
    "\n",
    "# Create a single-row, 3-column plot layout\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "# Loop over the three properties to generate subplots\n",
    "for i, ax in enumerate(axes):\n",
    "    # Get standard deviation of the target variable (for error normalization)\n",
    "    target = performance_targets[i + 1]\n",
    "    std_of_target = np.std(df_SISSO[target])\n",
    "\n",
    "    # Get prediction error data for the optimal model settings\n",
    "    test_data = get_test_data('./output/SISSO_results_publication/', 5, optimal_rungs[i], optimal_dimensions[i], target)\n",
    "    test_data[\"error\"] = abs(test_data[1] - test_data[2])\n",
    "    test_data[\"type\"] = 1  # Constant x-category\n",
    "\n",
    "    # Violin plot\n",
    "    sns.violinplot(\n",
    "        data=test_data, x=\"type\", y=\"error\",\n",
    "        inner=None, scale=\"area\", palette=colors,\n",
    "        alpha=1.0, linewidth=0.0, zorder=-2, ax=ax\n",
    "    )\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(\n",
    "        data=test_data, x=\"type\", y=\"error\",\n",
    "        showfliers=True, showmeans=True,\n",
    "        boxprops=boxprops, whiskerprops=whiskerprops,\n",
    "        capprops=capprops, medianprops=medianprops,\n",
    "        meanprops=meanprops, width=0.35, whis=(0.0, 95), ax=ax\n",
    "    )\n",
    "\n",
    "    # Axes formatting\n",
    "    ax.set_xticklabels([''], va='top', fontsize=16)\n",
    "    ax.set_ylim(0, std_of_target * 1.5)\n",
    "    ax.set_xlabel(xlabels[i])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Absolute Test Error')\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Secondary y-axis for percent-normalized view\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.set_ylim(0, 150)\n",
    "    if i == 2:\n",
    "        ax_twin.set_ylabel('Absolute Test Error/$\\mathrm{\\sigma}$ (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the errors for different materials and selectivity values, in the case of ethylene selectivity target\n",
    "\n",
    "# Load test data for ethylene selectivity prediction\n",
    "test_data = get_test_data('./output/SISSO_results_publication/', 5, 2, 3, 'S_ethylene')\n",
    "\n",
    "# Compute test errors\n",
    "test_data[\"abserror\"] = abs(test_data[1] - test_data[2])     # Absolute error\n",
    "test_data[\"error\"] = test_data[2] - test_data[1]             # Signed error\n",
    "\n",
    "# Extract catalyst identity for color coding\n",
    "test_data[\"labels\"] = test_data[0].str[:4]                   # First 4 characters e.g., 'PdAg'\n",
    "\n",
    "# Define color map and assign colors based on catalyst type\n",
    "color_map = {'PdAg': 'grey', 'PdAu': 'darkorange', 'PdCu': 'brown'}\n",
    "colors = test_data[\"labels\"].map(color_map)\n",
    "\n",
    "# Create side-by-side scatter plots ===\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n",
    "marker_size = 10\n",
    "\n",
    "# Plot 1: SISSO prediction vs true value (Parity plot)\n",
    "ax1.scatter(test_data[1], test_data[2], c=colors, s=marker_size)\n",
    "ax1.plot([-3, 2], [-3, 2], color='k', linestyle='--', linewidth=1)  # Diagonal reference line\n",
    "ax1.set_xlabel('$S_{\\mathrm{C_2H_4}}$')                             # True value\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}^{\\mathrm{SISSO}}$')            # Predicted value\n",
    "ax1.set_xlim(-2.6, 1)\n",
    "ax1.set_ylim(-2.6, 1)\n",
    "\n",
    "# Plot 2: Absolute error vs true value\n",
    "ax2.scatter(test_data[1], test_data[\"abserror\"], c=colors, s=marker_size)\n",
    "ax2.set_xlabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax2.set_ylabel('Absolute Test Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of model fit to the data \n",
    "# We look at the models trained on the entire dataset \n",
    "# at the optimal complexity identified by cross-validation\n",
    "targets=performance_targets[1:]\n",
    "for i in [0,1,2]:\n",
    "    df_fit=pd.read_csv('./output/SISSO_results_publication/full_dataset/'+targets[i]+'_r'+str(optimal_rungs[i])+'/models/train_dim_'+str(optimal_dimensions[i])+'_model_0.dat',\n",
    "                        comment='#',\n",
    "                        names=['material_Temperature_time',\n",
    "                            'target_true','target_fit',\n",
    "                            'feature_0','feature_1','feature_2']).set_index('material_Temperature_time')\n",
    "    df_SGD_selected[targets[i]+'_SISSO']=df_fit['target_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure global plot font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Create 3x2 grid of subplots (for three products at two temperatures)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "# Define visual properties for catalysts\n",
    "colors = ['grey'] * 3 + ['darkorange'] * 3 + ['brown'] * 3\n",
    "markers = ['s', '>', 'o'] * 3\n",
    "marker_size = 30\n",
    "\n",
    "# Loop over each of the 9 catalysts\n",
    "for i in range(9):    \n",
    "    # Get time-series data for current catalyst at 100°C and 150°C\n",
    "    cat_100 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_100']\n",
    "    cat_150 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_150']\n",
    "    \n",
    "    # Scatter plot for S_ethylene\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    \n",
    "    # Scatter plot for S_ethane\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    \n",
    "    # Scatter plot for S_C4\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "\n",
    "# Set axes limits\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.set_xlim(0, 406)\n",
    "ax1.set_ylim(-1.5, 1.5)\n",
    "ax2.set_ylim(-1.5, 1.5)\n",
    "ax3.set_ylim(0, 2.1)\n",
    "ax4.set_ylim(0, 2.1)\n",
    "ax5.set_ylim(0, 0.2)\n",
    "ax6.set_ylim(0, 0.2)\n",
    "\n",
    "# Set axis labels\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax3.set_ylabel('$S_{\\mathrm{C_2H_6}}$')\n",
    "ax5.set_ylabel('$S_{\\mathrm{C4}}$')\n",
    "ax5.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "ax6.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "\n",
    "# Tweak tick labels visibility for cleaner layout\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in [ax2, ax4, ax6]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Add subplot titles for temperature conditions\n",
    "ax1.set_title('$T_{\\mathrm{oven}} = 100\\,^\\circ\\mathrm{C}$')\n",
    "ax2.set_title('$T_{\\mathrm{oven}} = 150\\,^\\circ\\mathrm{C}$')\n",
    "\n",
    "# Add horizontal reference line at y=0 to the top row\n",
    "ax1.axhline(0, color='k', linewidth=0.5)\n",
    "ax2.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Add legend for catalysts (only once)\n",
    "ax2.legend(\n",
    "    labels=['measured', 'SISSO'],\n",
    "    loc=(1.04, 0.05),\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    "    fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model expressions\n",
    "# We look at the models trained on the entire dataset \n",
    "# at the optimal complexity identified by cross-validation\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    print('\\n SISSO Model for ', targets[i])\n",
    "    with open('./output/SISSO_results_publication/full_dataset/'+targets[i]+'_r'+str(optimal_rungs[i])+'/models/train_dim_'+str(optimal_dimensions[i])+'_model_0.dat', 'r') as file:\n",
    "         for j, line in enumerate(file, start=1):\n",
    "            if j in [1,4,5,6,7]:\n",
    "                print(line, end='')\n",
    "            if j >= 7:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model expressions of the top-50 ranked models for ethylene selectivity\n",
    "for i in range(50):\n",
    "    print('\\n Top '+str(i)+' SISSO Model for ', targets[0])\n",
    "    with open('./output/SISSO_results_publication/full_dataset/'+targets[0]+'_r'+str(optimal_rungs[0])+'_50_output_models/models/train_dim_'+str(optimal_dimensions[0])+'_model_'+str(i)+'.dat', 'r') as file:\n",
    "         for j, line in enumerate(file, start=1):\n",
    "            if j in [1,3,4,5,6,7]:\n",
    "                print(line, end='')\n",
    "            if j >= 7:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Exploiting the SGD and SISSO Models to Design New Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset of elemental properties \n",
    "df_elemental=pd.read_csv('./data/elemental_properties.csv').set_index('element')\n",
    "df_elemental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate descriptive parameters (primary features) for hypothetical materials\n",
    "# obtained with new elements mixed with palladium at different stoichiometries\n",
    "\n",
    "elements=df_elemental.index.tolist()\n",
    "elements.remove('Pd')\n",
    "\n",
    "# Chosen range of stoichiometries\n",
    "x_element=np.linspace(0.1, 0.9, 9).tolist()\n",
    "\n",
    "elemental_features=['IP', \n",
    "                    'EA', \n",
    "                    'PE',\n",
    "                    'bulk_int_dist', \n",
    "                    'E_coh', \n",
    "                    'B_0', \n",
    "                    'mu_C_critical_surf',\n",
    "                    'mu_C_critical_subsurf', \n",
    "                    'E_b_C_subsurf', \n",
    "                    'E_def_subsurf',\n",
    "                    'delta_M1_M2_subsurf', \n",
    "                    'BE_H_surf', \n",
    "                    'W_change_H',\n",
    "                    'd_band_center_surf', \n",
    "                    'BE_H_subsurf']\n",
    "\n",
    "rows = []\n",
    "\n",
    "for element in elements:\n",
    "    for x in x_element:\n",
    "        x_str = f\"{x:.1f}\" \n",
    "        x_comp_str = f\"{(1-x):.1f}\"\n",
    "        row={}\n",
    "        row['material']='Pd'+x_comp_str+element+x_str\n",
    "        for parameter in elemental_features:\n",
    "            feature_value=df_elemental.at[element, parameter]*x+df_elemental.at['Pd', parameter]*(1-x)\n",
    "            row['av_'+parameter]=feature_value\n",
    "        rows.append(row)\n",
    "           \n",
    "df_new_bimetallic = pd.DataFrame(rows).set_index('material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuzalize the hypothetical materials in the coordinates of the key materials-parameters identified by SGD\n",
    "# The SG rules are also shown\n",
    "\n",
    "fig, (ax1) = plt.subplots(1,1, constrained_layout=True, figsize=(4,4))\n",
    "marker_size=30\n",
    "ax1.vlines(4.6685,2.5659,3.05,color='red',linestyle='dashed')\n",
    "ax1.hlines(2.5659,4.6685,9,color='red',linestyle='dashed')\n",
    "ax1.fill_between([4.6685,9], 2.5659, 3.05, color='mistyrose')\n",
    "ax1.fill([7.8,6.05,4.33], [2.753,2.556,2.889], color='orange',  edgecolor='orange')\n",
    "\n",
    "ax1.scatter(df_SGD['av_E_b_C_subsurf'],df_SGD['av_bulk_int_dist'],c=color_entire_dataset,s=marker_size)\n",
    "ax1.scatter(df_SGD_selected['av_E_b_C_subsurf'],df_SGD_selected['av_bulk_int_dist'],c=color_SG,s=marker_size)\n",
    "ax1.scatter(df_new_bimetallic['av_E_b_C_subsurf'],df_new_bimetallic['av_bulk_int_dist'],c='grey',s=marker_size)\n",
    "\n",
    "ax1.set_ylim(2.4,3.05)\n",
    "ax1.set_xlim(4,8.5)\n",
    "ax1.arrow(4.6685, 2.7, 0.5, 0, head_width=0.015, head_length=0.2, color=color_SG)\n",
    "ax1.arrow(5.8, 2.5659, 0, 0.06, head_width=0.10, head_length=0.03, color=color_SG)\n",
    "\n",
    "ax1.set_xlabel('$\\\\widebar{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$ (eV)')  \n",
    "ax1.set_ylabel('$\\\\widebar{d_{\\mathrm{closest}}}$ ($\\mathrm{\\AA}$)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the SISSO model for ethylene selectivity\n",
    "def evaluate_SISSO_model_ethylene_selectivity(av_W_change_H,\n",
    "                                              av_d_band_center_surf,\n",
    "                                              av_BE_H_surf, \n",
    "                                              av_E_def_subsurf, \n",
    "                                              total_metal_loading, \n",
    "                                              particle_diameter,\n",
    "                                              av_BE_H_subsurf,\n",
    "                                              time, \n",
    "                                              temperature):\n",
    "    \n",
    "    if temperature == 150:\n",
    "        a=[4.813130462568657e-07, 3.727722063287428e+01,  -2.850231650770238e+00, -8.362104387720386e-02]\n",
    "    if temperature == 100:\n",
    "        a=[1.263789736634742e-06, 5.269016813835863e+01,  -2.661969356874947e+00, -1.704277305893994e-01]\n",
    "    \n",
    "    term_1=a[0]*(time / av_W_change_H) / (np.abs(av_d_band_center_surf - av_BE_H_surf))\n",
    "    term_2=a[1]*(av_E_def_subsurf * total_metal_loading * particle_diameter)\n",
    "    term_3=a[2]*(np.exp(8.365003e-04*((time+3.592461e+02) / (av_BE_H_subsurf+1.384560e+00))))\n",
    "    selectivity=term_1+term_2+term_3+a[3]\n",
    "    return(selectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predicted ethylene selectivity for new hypothetical bimetallic materials\n",
    "\n",
    "# The experimental parameters entering the SISSO model are unknown for new materials\n",
    "# We assume that the metal loading and mean particle diameter of these materials are\n",
    "# equal to the mean values among the materials in the training set\n",
    "mean_total_metal_loading=0.011755658627087199\n",
    "mean_particle_diameter=5.667903525046382\n",
    "\n",
    "# One temperature and two time-on-stream values are chosen\n",
    "temperature = 150  \n",
    "time = [40,400] \n",
    "\n",
    "# Chosen range of stoichiometries\n",
    "x_element=[0.45, 0.55, 0.65, 0.75, 0.85, 0.90]\n",
    "\n",
    "rows = []\n",
    "selectivities_40_min = []\n",
    "selectivities_400_min = []\n",
    "\n",
    "for element in elements:\n",
    "    selectivity_40_min=[]\n",
    "    selectivity_400_min=[]\n",
    "    for x in x_element:\n",
    "        x_str = f\"{x:.1f}\" \n",
    "        x_comp_str = f\"{(1-x):.1f}\"\n",
    "        row={}\n",
    "        row['material']='Pd'+x_comp_str+element+x_str\n",
    "        for parameter in elemental_features:\n",
    "            feature_value=df_elemental.at[element, parameter]*x+df_elemental.at['Pd', parameter]*(1-x)\n",
    "            row['av_'+parameter]=feature_value\n",
    "        row['S_ethylene_SISSO_40min_150C']=evaluate_SISSO_model_ethylene_selectivity(row['av_W_change_H'],\n",
    "                                                                                     row['av_d_band_center_surf'],\n",
    "                                                                                     row['av_BE_H_surf'],\n",
    "                                                                                     row['av_E_def_subsurf'],\n",
    "                                                                                     mean_total_metal_loading,\n",
    "                                                                                     mean_particle_diameter,\n",
    "                                                                                     row['av_BE_H_subsurf'],\n",
    "                                                                                     time[0],\n",
    "                                                                                     temperature)\n",
    "        row['S_ethylene_SISSO_400min_150C']=evaluate_SISSO_model_ethylene_selectivity(row['av_W_change_H'],\n",
    "                                                                                      row['av_d_band_center_surf'],\n",
    "                                                                                      row['av_BE_H_surf'],\n",
    "                                                                                      row['av_E_def_subsurf'],\n",
    "                                                                                      mean_total_metal_loading,\n",
    "                                                                                      mean_particle_diameter,\n",
    "                                                                                      row['av_BE_H_subsurf'],\n",
    "                                                                                      time[1],\n",
    "                                                                                      temperature)\n",
    "        rows.append(row)\n",
    "        selectivity_40_min.append(row['S_ethylene_SISSO_40min_150C'])\n",
    "        selectivity_400_min.append(row['S_ethylene_SISSO_400min_150C'])\n",
    "    selectivities_40_min.append(selectivity_40_min)\n",
    "    selectivities_400_min.append(selectivity_400_min)\n",
    "\n",
    "df_new_bimetallic = pd.DataFrame(rows).set_index('material')\n",
    "\n",
    "x_element_labels=[45, 55, 65, 75, 85, 90]\n",
    "    \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, constrained_layout=True, figsize=(8,4))\n",
    "im = ax1.imshow(selectivities_40_min ,cmap='viridis',vmin=-1.35, vmax=0.96, aspect='auto')\n",
    "im2 = ax2.imshow(selectivities_400_min ,cmap='viridis',vmin=-1.35, vmax=0.96, aspect='auto')\n",
    "ax1.set_ylabel('element')\n",
    "ax1.set_xlabel('$x_{\\mathrm{element}}$ (%)')\n",
    "ax1.set_xticks(ticks=[0,1,2,3,4,5], labels=x_element_labels)\n",
    "ax1.set_yticks(ticks=[0,1,2,3,4,5,6,7,8], labels=elements)\n",
    "fig.colorbar(im2, ax=ax2, label='Predicted $S_{\\mathrm{C_2H_4}}^{\\mathrm{SISSO}}$', fraction=0.050, pad=0.05)\n",
    "ax2.set_xlabel('$x_{\\mathrm{element}}$ (%)')\n",
    "ax2.set_xticks(ticks=[0,1,2,3,4,5], labels=x_element_labels)\n",
    "ax2.set_yticks(ticks=[0,1,2,3,4,5,6,7,8], labels='')\n",
    "ax1.set_title('$t_{\\mathrm{OS}}$ = 40 min')\n",
    "ax2.set_title('$t_{\\mathrm{OS}}$ = 400 min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Verification of SISSO Model Predictions for the Materials Pd1Ag12, Pd1Ag15, and Pd1Ag5Cu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_new = pd.read_csv('./data/performance_data_new_materials.csv')\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "size = 20\n",
    "time = np.arange(1, 400, 15)\n",
    "\n",
    "# Define composition and physical parameters\n",
    "compositions = [\n",
    "    {'label': 'Pd_Ag_1_12_150', 'comp': {'Pd': 1/13, 'Ag': 12/13}, 'd': 6.03, 'm': 0.0153, 'ax': ax1, 'title': 'Pd$_1$Ag$_{12}$'},\n",
    "    {'label': 'Pd_Ag_1_15_150', 'comp': {'Pd': 1/16, 'Ag': 15/16}, 'd': 7.04, 'm': 0.0161, 'ax': ax2, 'title': 'Pd$_1$Ag$_{15}$'},\n",
    "    {'label': 'Pd_Ag_Cu_1_5_1_150', 'comp': {'Pd': 1/7, 'Ag': 5/7, 'Cu': 1/7}, 'd': 5.80, 'm': 0.0145, 'ax': ax3, 'title': 'Pd$_1$Ag$_5$Cu$_1$'}\n",
    "]\n",
    "\n",
    "# Loop over each composition\n",
    "for cond in compositions:\n",
    "    comp = cond['comp']\n",
    "    ax = cond['ax']\n",
    "    \n",
    "    # Compute weighted average properties\n",
    "    av_W_change_H = sum(comp[e] * df_elemental.at[e, 'W_change_H'] for e in comp)\n",
    "    av_d_band_center_surf = sum(comp[e] * df_elemental.at[e, 'd_band_center_surf'] for e in comp)\n",
    "    av_BE_H_surf = sum(comp[e] * df_elemental.at[e, 'BE_H_surf'] for e in comp)\n",
    "    av_E_def_subsurf = sum(comp[e] * df_elemental.at[e, 'E_def_subsurf'] for e in comp)\n",
    "    av_BE_H_subsurf = sum(comp[e] * df_elemental.at[e, 'BE_H_subsurf'] for e in comp)\n",
    "\n",
    "    # Predict using SISSO model\n",
    "    predictions = []\n",
    "    for t in time:\n",
    "        y = evaluate_SISSO_model_ethylene_selectivity(\n",
    "            av_W_change_H,\n",
    "            av_d_band_center_surf,\n",
    "            av_BE_H_surf,\n",
    "            av_E_def_subsurf,\n",
    "            cond['m'],\n",
    "            cond['d'],\n",
    "            av_BE_H_subsurf,\n",
    "            t,\n",
    "            150\n",
    "        )\n",
    "        predictions.append(y)\n",
    "    \n",
    "    # Plot SISSO predictions\n",
    "    ax.scatter(time, predictions, color='red', s=size, marker='s')\n",
    "    \n",
    "    # Plot experimental data\n",
    "    data = data_new[data_new['material_Temperature'] == cond['label']]\n",
    "    ax.scatter(data['time (min)'], data['X_acetylene'], color='k', s=size, marker='x')\n",
    "    ax.scatter(data['time (min)'], data['S_ethylene'], color='blue', s=size, marker='s')\n",
    "    \n",
    "    # Axis formatting\n",
    "    ax.set_xlim(0, 400)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.hlines(0, 0, 400, color='k', linewidth=0.5)\n",
    "    ax.set_xlabel('$t_{\\mathrm{OS}}$(min)')\n",
    "    ax.set_title(cond['title'])\n",
    "\n",
    "# Add common y-label and clean up redundant ticks\n",
    "ax1.set_ylabel('$S$ or $X$, $T_{\\mathrm{oven}}=150\\degree$C')\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the detailed performance for all materials in the training set\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "size = 40\n",
    "temps = [50, 100, 150]\n",
    "colors = {\n",
    "    'X_acetylene': 'k',\n",
    "    'S_ethylene': 'blue',\n",
    "    'S_ethane': 'darkorange',\n",
    "    'S_C4': 'green',\n",
    "}\n",
    "markers = {\n",
    "    'X_acetylene': 'o',\n",
    "    'S_ethylene': 's',\n",
    "    'S_ethane': 's',\n",
    "    'S_C4': 's',\n",
    "}\n",
    "temp_lines = [50, 100, 150]\n",
    "\n",
    "for i, catalyst in enumerate(catalyst_list):\n",
    "    # Create 3 vertically stacked subplots with shared x-axis, and their twins for temperature\n",
    "    fig, axes = plt.subplots(3, 1, constrained_layout=True, figsize=(10, 8))\n",
    "    twin_axes = [ax.twinx() for ax in axes]\n",
    "\n",
    "    # Set common limits for main axes and twin axes\n",
    "    for ax, twin_ax in zip(axes, twin_axes):\n",
    "        ax.set_xlim(0, 406)\n",
    "        ax.set_ylim(-1, 2)\n",
    "        twin_ax.set_ylim(45, 330)\n",
    "\n",
    "    # Axis labels and legends setup\n",
    "    axes[1].set_ylabel('$X$ or $S$')\n",
    "    for twin_ax in twin_axes:\n",
    "        twin_ax.set_ylabel('$T_{\\\\mathrm{bed}} (\\\\mathrm{\\\\degree C})$', color='red')\n",
    "\n",
    "    axes[2].set_xlabel('$t_{\\\\mathrm{OS}}$ (min)')\n",
    "    axes[0].set_xticklabels([])\n",
    "    axes[1].set_xticklabels([])\n",
    "\n",
    "    # Plotting loop for each temperature subplot\n",
    "    for ax, twin_ax, T in zip(axes, twin_axes, temps):\n",
    "        # Filter data for catalyst and temperature\n",
    "        data = df_initial.loc[df_initial['material_Temperature'] == f'{catalyst}_{T}']\n",
    "        \n",
    "        # Title for the first subplot includes catalysevaluate_SISSO_model_ethylene_selectivityt caption\n",
    "        if T == 50:\n",
    "            ax.set_title(f'{catalyst_list_caption[i]}\\n $T_{{\\\\mathrm{{oven}}}}={T}\\\\mathrm{{\\\\degree}}$ C')\n",
    "        else:\n",
    "            ax.set_title(f'$T_{{\\\\mathrm{{oven}}}}={T}\\\\mathrm{{\\\\degree}}$ C')\n",
    "\n",
    "        # Plot conversion/selectivities\n",
    "        for col, color in colors.items():\n",
    "            ax.scatter(data['time (min)'], data[col], color=color, s=size, marker=markers[col])\n",
    "\n",
    "        # Plot temperature on twin axis\n",
    "        twin_ax.scatter(data['time (min)'], data['T_catbed (C)'], color='red', s=size, marker='x')\n",
    "\n",
    "    # Legends outside loop to avoid duplicates\n",
    "    axes[0].legend(\n",
    "        ['$X_{\\\\mathrm{C_2H_2}}$', '$S_{\\\\mathrm{C_2H_4}}$', '$S_{\\\\mathrm{C_2H_6}}$', '$S_{\\\\mathrm{C_4}}$'],\n",
    "        frameon=True, fontsize=14, loc=(1.15, 0.4)\n",
    "    )\n",
    "    twin_axes[0].legend(['$T_{\\\\mathrm{bed}}$'], loc=(1.15, 0.2), frameon=True, fontsize=14)\n",
    "\n",
    "    # Add horizontal dashed lines on twin axes to mark oven temperatures\n",
    "    for twin_ax, T_line in zip(twin_axes, temp_lines):\n",
    "        twin_ax.hlines(T_line, 0, 406, linestyle='dashed', color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
