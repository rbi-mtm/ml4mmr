{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Subgroup Discovery and SISSO\n",
    "\n",
    "In this tutorial, we will utilize the subgroup-discovery (SGD) and the sure-independence screening and sparsifying operator (SISSO) symbolic-regression approaches to obtain interpretable models for materials' properties or functions. \n",
    "\n",
    "The tutorial is based on the approach and data of the following publication:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "J. M. Mauß, K. Kley, R. Khobragade, N-K. Tran, J. De Bellis, F. Schüth, M. Scheffler, L. Foppa: <span style=\"font-style: italic;\">\"Modeling Time-On-Stream Catalyst Reactivity in the Selective Hydrogenation of Concentrated Acetylene Streams Under Industrial Conditions via Experiments and AI\"</span>, ChemRxiv,10.26434/chemrxiv-2025-vf7hd-v2 (2025) <a href=\"https://chemrxiv.org/engage/chemrxiv/article-details/67ea84986dde43c908d79032\" target=\"_blank\">[Paper]</a>.\n",
    "</div>\n",
    "\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "## Subgroup Discovery (SGD)\n",
    "The SGD approach is based on a data set containing a target quantity of interest and many candidate descriptive parameters (primary features), whose values are known for all the samples in the data set. The target quantity can be the materials property of interest. The candidate descriptive parameters, in turn, characterize the materials and the underlying processes that are potentially relevant for the materials property. \n",
    "\n",
    "SGD starts by generating a pool of propositions, statements about the candidate descriptive parameters that apply only to a portion of the data set. For the case of continuous parameters, the propositions are inequalities constraining the values of the descriptive parameters. Then, SGD identifies selectors, statements formed by a number of propositions combined via the “AND” connector (denoted “∧”), that result in the selection of SGs of data points associated with the most outstanding distributions of the target values. The quality function $Q(SG,\\widetilde{P})$ measures how outstanding a SG is. It has the form \n",
    "\n",
    "\\begin{equation}\n",
    " Q(SG,\\widetilde{P}) = \\frac{s(SG)}{s(\\widetilde{P})}* u(SG,\\widetilde{P})\n",
    "\\end{equation} \n",
    "\n",
    "where the first term, the coverage, contains the ratio between the number of data points in the subgroup, $s(SG)$, and the total number of data points in the entire dataset, $s(\\widetilde{P})$. This coverage term controls the subgroup size and prevents that very small SGs with little statistical significance are selected. The second term, $u(SG,\\widetilde{P})$, is called utility function and it measures the dissimilarity between the SG and the entire data set, denoted $\\widetilde{P}$. We refer to the dataset as $\\widetilde{P}$ in order to stress that it is a sample of the entire, unknown population $P$. Many utility functions can be used in SGD depending on the scientific question and desired values of the target quantity. In this tutorial, we will compare the results obtained with different utility functions.\n",
    "\n",
    "\n",
    "The outcome of the SGD analysis are the selectors resulting in the highest $Q(SG,\\widetilde{P})$ values, i.e., in the most outstanding SGs. They can be seen as rules describing the SG behavior. The parameters entering these propositions are, in turn, the key, most relevant, parameters associated with the SG, out of all the initially offered candidate descriptive parameters. Because the SG search is performed by maximizing a function measuring how outstanding specific subselections of data points are, this approach identifies a local behavior.\n",
    "\n",
    "The SGD approach is presented in more details in:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> B. R. Goldsmith, M. Boley, J. Vreeken, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">Uncovering structure-property relationships of materials by subgroup discovery.</span>, New J. Physics 19, 013031 (2017) <a href=\"https://doi.org/10.1088/1367-2630/aa57c2\" target=\"_blank\">[PDF]</a> .\n",
    "</div>\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> M. Boley, B. R. Goldsmith,  L. M. Ghiringhelli, J. Vreeken: <span style=\"font-style: italic;\">Identifying consistent statements about numerical data with dispersion-corrected subgroup discovery</span>, Data Min. Knowl. Discov. 31, 1391 (2017) <a href=\"https://doi.org/10.1007/s10618-017-0520-3\" target=\"_blank\">[PDF]</a> .\n",
    "</div>\n",
    "\n",
    "In this tutorial, we use the SGD algorithm as implemented in realkd, available in https://bitbucket.org/realKD/.\n",
    "\n",
    "\n",
    "## Sure-Independence Screening and Sparsifying Operator (SISSO)\n",
    "\n",
    "Symbolic regression (SR) identifies nonlinear analytical expressions relating a target property to key parameters, out of many offered candidate descriptive parameters (primary features). Thus, it is a possible avenue for linking physical reasoning and data-centric approaches when modelling materials properties and functions. The candidate descriptive parameters are typically physical quantities that are related to possible underlying processes governing the property. Because the key parameters can be directly identified by inspecting the analytical expressions, the models resulting from the SR analysis are interpretable. Another advantage of SR is that it can learn a representation for the property of interest based on data sets that are considered small (e.g., $10^2$ data points or less) compared to the trainig datasets of widely used artificial-intelligence methods such as artificial neural networks. Thus, SR is particularly suited for experimental materials-science problems, in which consistent and well characterized sets of materilas might be scarce. \n",
    "\n",
    "SISSO combines SR with compressed sensing, and it is a deterministic approach to obtain the mentioned analytical expressions. SISSO starts with the collection of physical input parameters, candidate descriptive parameters or primary features. Then, a more expansive pool of expressions is iteratively built by exhaustively applying a set of mathematical operators to both the primary features and previously generated expressions. This step is referred to as the feature-creation step. The number of recursive applications of the operators used to construct the pool of expressions is called the rung (denoted $q$). Finally, compressed sensing is used to identify the best $D$-dimensional linear model by performing an $l_0$ regularization on a subspace $S$ of all generated expressions, where $S$ is selected using SIS. The Pearson correlation is used as the projection score. \n",
    "\n",
    "The outcome of the SISSO analysis is a low $D$-dimensional descriptor vector containing, as components, the expressions selected from the pool of expressions. A SISSO-derived model for a property $S$ has the form\n",
    "\n",
    "\\begin{equation}\n",
    " S^{\\mathrm{SISSO}} = \\sum_{i=0}^{D} c_i d_i\n",
    "\\end{equation} \n",
    "\n",
    "where $c_i$ are fitting coefficients and $d_i$ are the descriptor components. We note that $q$ and $D$ are *hyperparameters* of the SISSO model. In this tutorial, we will utilize a cross-validation scheme in order to determine them.\n",
    "\n",
    "The SISSO algorithm is presented in more details in:\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "R. Ouyang, S. Curtarolo, E. Ahmetcik, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">SISSO: a compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates</span>, Phys. Rev. Materials  2, 083802 (2018) <a href=\"https://journals.aps.org/prmaterials/abstract/10.1103/PhysRevMaterials.2.083802\" target=\"_blank\">[PDF]</a>.\n",
    "</div>\n",
    "\n",
    "## Focused AI Approach Combining SGD and SISSO\n",
    "\n",
    "The two-step focused AI modeling approach described here takes into account two different materials functions or targets $Y_1$ and $Y_2$. \n",
    "\n",
    "In the first step, SGD is applied to identify descriptions of SGs of materials that exhibit a specific distribution of $Y_1$ values, such as a narrow distribution or a distribution concentrated in high values. SGD generates a set of inequalities describing the SG.\n",
    "\n",
    "In the second step, SISSO is used to quantitatively model $Y_2$ for the subset of materials identified by SGD in the first step. SISSO generates a regression model describing $Y_2$. \n",
    "\n",
    "\n",
    "The outcome of the AI analysis is a SGD model that indicates whether a given material is associated with a desired distribution of $Y_1$. This classification is then subsequently quantified by a SISSO analysis which predicts the second target for the materials that were indentified by SGD. The SISSO models for do not attempt to describe all materials simultaneously, but they focus on the situations of interest that were first identified by SGD. Therefore, in this focused AI approach, SGD identifies a description of a specific data space in which the SISSO model is trained.\n",
    "\n",
    "The focused AI approach is general and can be applied to many materials properties or functions. In this tutorial, it will be demonstrated in the context of heterogeneous catalyis.\n",
    "\n",
    "## Application: Modeling the Performance of Pd-Based Alloys Applied in the Selective Hydrogenation of Concentrated Acetylene Streams\n",
    "\n",
    "Heterogeneous catalysis is a key technology for enabling the efficient and sustainable production of chemicals and fuels. Chemical reactions catalyzed by solids are, nevertheless, governed by a concerted and intricate interplay of multiple processes at different scales. The complex bond-breaking and -forming reaction networks on the catalyst surface, the dynamic restructuring of the material under reaction conditions, and the transport of reactants and products to/from the catalytic surface are some of these processes. In order to model the intricacy of heterogeneous catalysis, we will combine experimental and theoretical data and identify correlations that bridge the complexity between descriptive design parameters encoding the underlying processes, and catalyst performance. Thus, we accelerate the discovery of improved, new materials while providing inisghts on the most relevant underlying processes. \n",
    "\n",
    "The focused AI approach will be demonstrated to model the measured time-on-stream-dependent reactivity of palladium-based bimetallic catalysts. These materials are synthesized via mechanochemistry and applied in the selective hydrogenation of concentrated acetylene streams under industrially relevant pressures, resulting from a hypothetical electric plasma-assisted methane-to-ethylene process. Unlike the well-established hydrogenation of diluted acetylene streams of naphtha steam cracking, the hydrogenation of concentrated acetylene streams remains largely underexplored due to the harsh reaction conditions and explosive nature of acetylene. This precludes operando characterization or atomistic simulations to investigate catalyst time-on-stream behavior under realistic conditions.\n",
    "\n",
    "The first target performance of the AI approach is the acetylene conversion. The conversion reflects the catalyst activity, i.e., its ability to transform the reactant molecule into products. Thus, high acetylene conversion values are desirable. \n",
    "\n",
    "The second target performance is the selectivity. The selectivity reflects the relative amount of a specific product formed from the initial reactant. Three different selectivities are considered, towards the products ethylene, ethane, and C$_4$ products.  In the selective acetylene hydrogenation, the desired product is ethylene. Thus, high selectivity values for ethylene are desirable. \n",
    "\n",
    "The focused AI approach first uses SGD to identify descriptions of materials and reaction condition resulting in noticeable acetylene conversion. Then, it models the time-dependent selectivity focused on high acetylene conversion via the SISSO approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Modules and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing the required modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from csv file\n",
    "df=pd.read_csv('./data/performance_data.csv')\n",
    "\n",
    "# The analysis focuses on the intial reaction times\n",
    "# Data points associated to nonphysical selectivity values are excluded\n",
    "df_initial=df.loc[(df['time (min)'] < 406)\n",
    "                 & (df['S_ethane'] > -0.1)\n",
    "                 & (df['S_ethane'] < 2.1)\n",
    "                 & (df['S_ethylene'] < 1)\n",
    "                 & (df['S_ethylene'] > -1.2)]\n",
    "\n",
    "# The dataset contains 12 materials measured at three temperatures (50, 100, and 150 C) \n",
    "# and multiple times on stream. In total, there are 1076 data points.\n",
    "print(len(df_initial))\n",
    "df_initial.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Target Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analysis focuses on the target performances: acetylene conversion,\n",
    "# ethylene selectivity, ethane selectivity, and C4 selectivity\n",
    "performance_targets =['X_acetylene',\n",
    "                     'S_ethylene',\n",
    "                     'S_ethane',\n",
    "                     'S_C4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The acetyelene conversion and ethylene selectivity are plotted in the following figure\n",
    "# Define catalyst names and captions\n",
    "catalyst_list = [f'PdAg_1_{i}' for i in [9, 5, 1]] + \\\n",
    "                [f'PdAu_1_{i}' for i in [9, 5, 1]] + \\\n",
    "                [f'PdCu_1_{i}' for i in [9, 5, 1]] + ['Ag', 'Au', 'Cu']\n",
    "\n",
    "catalyst_list_caption = [r'Pd$_1$Ag$_9$', r'Pd$_1$Ag$_5$', r'Pd$_1$Ag$_1$',\n",
    "                         r'Pd$_1$Au$_9$', r'Pd$_1$Au$_5$', r'Pd$_1$Au$_1$',\n",
    "                         r'Pd$_1$Cu$_9$', r'Pd$_1$Cu$_5$', r'Pd$_1$Cu$_1$',\n",
    "                         'Ag', 'Au', 'Cu']\n",
    "\n",
    "# Predefine temperatures and storage containers\n",
    "temperatures = [50, 100, 150]\n",
    "sel_matrices, act_matrices, masks = {}, {}, {}\n",
    "\n",
    "# Extract data for each catalyst and temperature\n",
    "for T in temperatures:\n",
    "    sel_matrices[T], act_matrices[T] = [], []\n",
    "    for cat in catalyst_list:\n",
    "        data = df_initial[df_initial['material_Temperature'] == f\"{cat}_{T}\"]\n",
    "        sel = list(data['S_ethylene'].iloc[::3])\n",
    "        act = list(data['X_acetylene'].iloc[::3])\n",
    "        sel_matrices[T].append(sel)\n",
    "        act_matrices[T].append(act)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    sel_np = np.array(sel_matrices[T])\n",
    "    act_np = np.array(act_matrices[T])\n",
    "    \n",
    "    # Mask values where conversion is below 99%\n",
    "    masks[T] = np.ma.masked_where(act_np <= 0.99, sel_np)\n",
    "\n",
    "# Plotting \n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "# Shared colormap\n",
    "cmap = cm.get_cmap('viridis').copy()\n",
    "cmap.set_bad(color='lightgrey')\n",
    "\n",
    "# Shared x-ticks from any dataset\n",
    "x_ticks = list(df_initial[df_initial['material_Temperature'] == f\"{catalyst_list[0]}_{temperatures[0]}\"]['time (min)'].iloc[::3])\n",
    "\n",
    "# Create subplots for each temperature\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(masks[T], cmap=cmap, vmin=-1, vmax=0.75)\n",
    "\n",
    "    # Axis labels and ticks\n",
    "    ax.set_xlabel(r'$t_{\\mathrm{OS}}$ (min)')\n",
    "    ax.set_xticks(range(len(x_ticks)))\n",
    "    ax.set_xticklabels(x_ticks, rotation=90)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.set_yticks(range(len(catalyst_list_caption)))\n",
    "        ax.set_yticklabels(catalyst_list_caption)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Horizontal lines to separate metal groups\n",
    "    for y in range(3, masks[T].shape[0], 3):\n",
    "        ax.axhline(y - 0.5, color='white', linestyle='--', linewidth=1.8)\n",
    "\n",
    "    ax.set_title(fr'$T_{{\\mathrm{{oven}}}}={T} \\degree$ C')\n",
    "\n",
    "# Shared colorbar\n",
    "fig.colorbar(im, ax=axes, shrink=0.475, label=r'$S_{\\mathrm{C_2H_4}}$ at $X_{\\mathrm{C_2H_2}} \\geq 0.99$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Candidate Descriptive Parameters (Primary Features)\n",
    "\n",
    "As candidate descriptive parameters (primary features) characterizing the materials and reaction conditions, we collected four parameters from the experimental characterization of the materials by energy dispersive X-ray analysis in a scanning electron microscope (EDX-SEM), high-resolution transmission-electron microscopy (TEM), and N$_2$ physisorption, such as the mean particle diameter ($D_\\mu$) and the specific surface area ($s_{\\mathrm{BET}}$).\n",
    "Additionally, we included three experimental elemental (free-atom) properties and three experimental bulk properties as parameters reflecting the chemistry of the bulk of the metal NPs, such as the ionization potential ($IP$) and the closest interatomic distance ($d_{\\mathrm{closest}}$). Finally, we utilized nine parameters reflecting the properties of the surfaces of the metal NPs and the interaction of carbon and hydrogen with the surface and subsurface. These parameters were calculated by density functional theory under the generalized gradient approximation (DFT-GGA) on low-index model surfaces. Examples of such parameters are the energy of the $d$-band center($\\epsilon_d$) and the binding energy of subsurface hydrogen and carbon ($E_{\\mathrm{b,H}}^{\\mathrm{sub}}$ and $E_{\\mathrm{b,C}}^{\\mathrm{sub}}$, respectively). The elemental, bulk, and surface-related properties were converted into materials-specific parameters by taking the composition average, indicated by the bar in $\\overline{\\phi}$, where $\\phi$ is an elemental, bulk, or surface parameter. Finally, $t_{\\mathrm{OS}}$ and $T_{\\mathrm{oven}}$ were used as parameters related to the applied reaction conditions. In total, 21 candidate descriptive parameters were collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect the values of the candidate descriptive parameters \n",
    "# plot the distribution of their values, and analyze the correlations between them\n",
    "\n",
    "reaction_parameters=['time (min)','T_reactor (C)']\n",
    "\n",
    "materials_parameters=['total_metal_loading', \n",
    "                      'particle_diameter (nm)',\n",
    "                      'std_dev (nm)', \n",
    "                      'surface_area (m^2/g)',\n",
    "                      'av_IP (eV)', \n",
    "                      'av_EA (eV)', \n",
    "                      'av_PE',\n",
    "                      'av_bulk_int_dist (A)', \n",
    "                      'av_E_coh (eV/atom)', \n",
    "                      'av_B_0 (Gpa)', \n",
    "                      'av_mu_C_critical_surf (eV)',\n",
    "                      'av_mu_C_critical_subsurf (eV)', \n",
    "                      'av_E_b_C_subsurf (eV)', \n",
    "                      'av_E_def_subsurf (eV)',\n",
    "                      'av_delta_M1_M2_subsurf', \n",
    "                      'av_BE_H_surf (eV)', \n",
    "                      'av_W_change_H (eV)',\n",
    "                      'av_d_band_center_surf (eV)', \n",
    "                      'av_BE_H_subsurf (eV)']\n",
    "\n",
    "materials_parameters_labels=['$w_{\\mathrm{metal}}$' , \n",
    "                             '$D_\\mu$', \n",
    "                             '$D_\\sigma$',\n",
    "                             '$s_{\\mathrm{BET}}$', \n",
    "                             '$\\overline{IP}$', \n",
    "                             '$\\overline{EA}$', \n",
    "                             '$\\overline{EN}$',\n",
    "                             '$\\overline{d_{\\mathrm{closest}}}$', \n",
    "                             '$\\overline{E_{\\mathrm{coh}}}$', \n",
    "                             '$\\overline{B_{\\mathrm{0}}}$',\n",
    "                             '$\\overline{\\mu_{\\mathrm{C}}^{\\mathrm{surf}}}$',\n",
    "                             '$\\overline{\\mu_{\\mathrm{C}}^{\\mathrm{sub}}}$',\n",
    "                             '$\\overline{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$', \n",
    "                             '$\\overline{E_{\\mathrm{d,C}}^{\\mathrm{sub}}}$',\n",
    "                             '$\\overline{\\delta_{\\mathrm{C}}^{\\mathrm{sub}}}$', \n",
    "                             '$\\overline{E_{\\mathrm{b,H}}^{\\mathrm{surf}}}$', \n",
    "                             '$\\overline{\\Delta W_{\\mathrm{H}}^{\\mathrm{surf}}}$',\n",
    "                             '$\\overline{\\epsilon_d}$',\n",
    "                             '$\\overline{E_{\\mathrm{b,H}}^{\\mathrm{sub}}}$']\n",
    "\n",
    "features=reaction_parameters+materials_parameters\n",
    "\n",
    "df_materials_parameters = df_initial[materials_parameters].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram grid\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over each parameter and its label\n",
    "for i, (param, label) in enumerate(zip(materials_parameters, materials_parameters_labels)):\n",
    "    ax = axes[i]\n",
    "    ax.hist(df_materials_parameters[param], bins=20, color='k')\n",
    "    ax.set_title(label)\n",
    "    #ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(len(materials_parameters), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Distribution of Material Parameters', fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "fig,ax1 = plt.subplots(1,1, constrained_layout=True, figsize=(5,5))\n",
    "\n",
    "\n",
    "matrix = np.triu(df_materials_parameters)\n",
    "pearson_correlation = df_materials_parameters.corr(method='pearson')\n",
    "sns.heatmap(pearson_correlation, \n",
    "            xticklabels=materials_parameters_labels,\n",
    "            yticklabels=materials_parameters_labels,\n",
    "            cmap='RdBu_r',\n",
    "            annot=False,\n",
    "            linewidth=0.5,\n",
    "            vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SGD Identification of Descriptions of Materials and Reaction Conditions Resulting in Noticeable Acetylene Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify columns to extract (index, target, and features to be used in SGD)\n",
    "columns_to_extract =['material_Temperature','material_Temperature_time']+performance_targets+features\n",
    "\n",
    "# Extract the specified columns\n",
    "df_SGD = df_initial[columns_to_extract].copy().set_index('material_Temperature_time')\n",
    "\n",
    "# Rename columns by removing the units (in parentheses)\n",
    "df_SGD.columns = [re.sub(r'\\s*\\(.*?\\)', '', col).strip() for col in df_SGD.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input files for SGD\n",
    "def write_input_SGD(path, df, id_job, n_cutoffs, algo, dev, n_res, n_seeds, target_key, weight):\n",
    "    \"\"\"\n",
    "    creates the two input files necessary to run SGD with realkd:\n",
    "    i) a .json file with calculation details, named \"id_job.json\", and\n",
    "    ii) a .xarf file with the data set, named \"id_job.xarf\".\n",
    "    function arguments: path(str): path to the folder where the files \n",
    "                                   will be written\n",
    "               df(data frame): data set containing the values for the \n",
    "                               candidate descriptive parameters and for\n",
    "                               the target for all materials\n",
    "               id_job(str): job name\n",
    "               n_cutoffs(int): number of cutoffs to be used in k-Means\n",
    "                               clustering to generate the propositions\n",
    "               algo(str): SG search algorithm:\n",
    "                          PMM_SAMPLER \n",
    "                          EMM_SAMPLER\n",
    "                          EXCEPTIONAL_SUBGROUP_BESTFIRST_BRANCHANDBOUND\n",
    "                          \n",
    "                          PMM_SAMPLER uses (std(SG)-std(P))/std(P) as utility function\n",
    "                          whereas EMM_SAMPLER/EXCEPTIONAL_SUBGROUP_BESTFIRST_BRANCHANDBOUND \n",
    "                          use the function specified in dev\n",
    "               \n",
    "               dev(str): deviation measure when using EMM_SAMPLER: \n",
    "                         cumulative_jensen_shannon_divergence\n",
    "                         normalized_positive_mean_shift\n",
    "                         normalized_negative_mean_shift\n",
    "                         normalized_positive_median_shift\n",
    "                         normalized_negative_median_shift\n",
    "                         \n",
    "               n_res(int): number of results, i.e., number of top-ranked\n",
    "                           SGs to display\n",
    "               n_seeds(int): number of seeds to use for the SG search\n",
    "               target_key(str): label of the variable to be used as target quantity in SGD\n",
    "    \"\"\"\n",
    "    df.to_csv(path+'/'+id_job+'.csv')\n",
    "    with open(path+'/'+id_job+'.csv', 'r') as file_in:\n",
    "        data = file_in.read().splitlines(True)\n",
    "        \n",
    "    file_out = open(path+'/'+id_job+'.xarf', 'w')\n",
    "    file_out.write('@relation '+id_job+'\\n')\n",
    "    file_out.write('@attribute materials name\\n')\n",
    "    for variable in list(df.columns):\n",
    "        file_out.write('@attribute '+variable+' numeric\\n')\n",
    "    file_out.write(\"@data\\n\")\n",
    "    file_out.close()\n",
    "\n",
    "    with open(path+'/'+id_job+'.xarf', 'a') as file_out:\n",
    "        file_out.writelines(data[1:])\n",
    "        file_out.close()\n",
    "    \n",
    "    input_file = {}\n",
    "    input_file = {\"type\" : \"productWorkScheme\",\n",
    "                  \"id\" : id_job,\n",
    "                  \"workspaces\" : [ {\n",
    "                                \"type\" : \"workspaceFromXarf\",\n",
    "                                \"id\" : id_job,\n",
    "                                \"datafile\" : id_job+\".xarf\",\n",
    "                                \"propScheme\": {\"type\": \"standardPropScheme\",\n",
    "                                                \"defaultMetricRule\": {\"type\": \"kmeansPropRule\",\n",
    "                                                                       \"numberOfCutoffs\": n_cutoffs,\n",
    "                                                                       \"maxNumberOfIterations\": 1000}}} ],\n",
    "                    \"computations\" : [ {\n",
    "                                \"type\" : \"legacyComputation\",\n",
    "                                \"id\" : \"subgroup_analysis\",\n",
    "                                \"algorithm\" : algo,\n",
    "                                \"parameters\" : {\n",
    "                                    \"dev_measure\": dev,\n",
    "                                    \"attr_filter\" : \"[]\",\n",
    "                                    \"cov_weight\" : weight,\n",
    "                                    \"num_res\" : n_res,\n",
    "                                    \"num_seeds\" : n_seeds,\n",
    "                                    \"targets\" : \"[\"+target_key+\"]\"\n",
    "                                             }\n",
    "                  }],\n",
    "                  \"computationTimeLimit\" : 3600000\n",
    "                     }\n",
    "    with open(path+'/'+id_job+'.json','w') as outfile:\n",
    "        json.dump(input_file, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention ⚠️\n",
    "\n",
    "We will use the standard-deviation-reduction utility function, defined by: \n",
    "\n",
    "\\begin{equation}\n",
    " u(SG,\\widetilde{P}) = \\frac{std(\\widetilde{P})-std(SG)}{std(\\widetilde{P})}, \n",
    "\\end{equation} \n",
    "\n",
    "where $std(SG)$ and $std(\\widetilde{P})$ are the standard deviation of the distributions of the target in the SG and in the whole data set, respectively. By using this utility function, we favor the selection of SGs that present narrow distribution of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the SGD job\n",
    "job_id='SGD_results_publication'\n",
    "\n",
    "# Speficy SGD parameters\n",
    "# Number of thresholds (k in k-means clustering)\n",
    "n_clusters=20\n",
    "\n",
    "#Number of seeds used to initialize the SGD search algorithm (opportunistic pruning)\n",
    "n_seeds=50000\n",
    "\n",
    "#Number of SGD solutions to be printed\n",
    "n_results=5000\n",
    "\n",
    "#Check if old files exist for the specified job_id and remove them\n",
    "#dirpath = os.path.join('./output/', job_id)\n",
    "#if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "#    shutil.rmtree(dirpath)\n",
    "\n",
    "# Write input files\n",
    "# The utility function \"standard deviation reduction\" is chosen (\"PMM_SAMPLER\")\n",
    "#write_input_SGD('./', \n",
    "#            df_SGD.drop(['material_Temperature', 'time', 'S_ethylene', 'S_ethane','S_C4'], axis=1), \n",
    "#            job_id, \n",
    "#            n_clusters,\n",
    "#            'PMM_SAMPLER',\n",
    "#            '',\n",
    "#            n_results, \n",
    "#            n_seeds,\n",
    "#            columns_to_extract[2],\n",
    "#            1.0)\n",
    "# Run SGD  \n",
    "#os.system('java -jar realkd-0.7.2-jar-with-dependencies.jar '+job_id+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze the results of SGD\n",
    "def analyze_output_SGD(file_results):\n",
    "    \n",
    "    list_coverages=[]\n",
    "    list_utility_function=[]\n",
    "    list_quality_function=[]\n",
    "    list_target_mean=[]\n",
    "    list_constraints=[]\n",
    "    \n",
    "    with open(file_results) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for index in range(len(data)):\n",
    "            coverage=data[index].get('measurements')[0].get('value')\n",
    "            utility_function=data[index].get('measurements')[1].get('value')\n",
    "            quality_function=coverage*utility_function\n",
    "            target_mean=data[index].get('descriptor').get('targetLocalModel').get('means')\n",
    "            list_attributes=data[index].get('descriptor').get('selector').get('attributes')\n",
    "            list_operators=[]\n",
    "            list_cutoffs=[]\n",
    "            constraints=[]\n",
    "            for i in list(range(0,len(list_attributes))):\n",
    "                list_operators.append(data[index].get('descriptor').get('selector').get('constraints')[i].get('type'))\n",
    "                list_cutoffs.append(round(data[index].get('descriptor').get('selector').get('constraints')[i].get('value'),4))\n",
    "\n",
    "            list_operators = [op.replace('lessOrEquals', '<=') for op in list_operators]\n",
    "            list_operators = [op.replace('greaterOrEquals', '>=') for op in list_operators]\n",
    "            list_operators = [op.replace('lessThan', '<') for op in list_operators]\n",
    "            list_operators = [op.replace('greaterThan', '>') for op in list_operators]\n",
    "    \n",
    "            for i in list(range(0,len(list_attributes))):\n",
    "                if i == 0:\n",
    "                    constraints=list_attributes[0]+list_operators[0]+str(list_cutoffs[0])\n",
    "                else:\n",
    "                    constraints=constraints+' & '+list_attributes[i]+list_operators[i]+str(list_cutoffs[i])\n",
    "            list_coverages.append(coverage)\n",
    "            list_utility_function.append(utility_function)\n",
    "            list_quality_function.append(quality_function)\n",
    "            list_target_mean.append(*target_mean)\n",
    "            list_constraints.append(constraints)\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(list(zip(list_coverages,\n",
    "                               list_utility_function,\n",
    "                               list_quality_function,\n",
    "                              list_target_mean,\n",
    "                               list_constraints)), \n",
    "                      columns =['coverage','utility','quality','target_mean','constraints'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with the SGD results\n",
    "file_results='./output/'+job_id+'/'+os.listdir('./output/'+job_id+'/')[0]+'/results/'+job_id+'_subgroup_analysis.json'\n",
    "\n",
    "# The results are stored in a dataframe that shows a list of SGs ranked by their quality-function values \n",
    "df_SGD_results=analyze_output_SGD(file_results)\n",
    "df_SGD_results.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the rules associated to the SG presenting the highest value of quality function\n",
    "df_SGD_results.iloc[0]['constraints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of target performance metrics in the entire dataset\n",
    "# and in the identified SG\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, constrained_layout=True, figsize=(6,6))\n",
    "\n",
    "# Apply the SG rules (constraints) to the dataset\n",
    "df_SGD_selected=df_SGD.query(df_SGD_results['constraints'][0])\n",
    "\n",
    "color_entire_dataset='black'\n",
    "color_SG='red'\n",
    "n_bins=20\n",
    "\n",
    "ax1.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax1.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "axins = inset_axes(ax1, width=\"65%\", height=\"35%\",loc=2)\n",
    "axins.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "axins.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "axins.set_ylim(0,40)\n",
    "\n",
    "ax2.hist(df_initial['S_ethylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax2.hist(df_SGD_selected['S_ethylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax3.hist(df_initial['S_ethane'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax3.hist(df_SGD_selected['S_ethane'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax4.hist(df_initial['S_C4'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax4.hist(df_SGD_selected['S_C4'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax1.set_ylabel('Counts')\n",
    "ax2.set_ylabel('Counts')\n",
    "ax3.set_ylabel('Counts')\n",
    "ax4.set_ylabel('Counts')\n",
    "\n",
    "ax1.set_xlabel('$X_{\\mathrm{acetylene}}$')\n",
    "ax2.set_xlabel('$S_{\\mathrm{ethylene}}$')\n",
    "ax3.set_xlabel('$S_{\\mathrm{ethane}}$')\n",
    "ax4.set_xlabel('$S_{\\mathrm{C4}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the SG identified in the publication,\n",
    "# we plot the 12 materials in the coordinates of the two materials-related parameters appearing in the rules\n",
    "fig, (ax1) = plt.subplots(1,1, constrained_layout=True, figsize=(4,4))\n",
    "marker_size=30\n",
    "ax1.vlines(4.6685,2.5659,3.05,color='red',linestyle='dashed')\n",
    "ax1.hlines(2.5659,4.6685,9,color='red',linestyle='dashed')\n",
    "ax1.fill_between([4.6685,9], 2.5659, 3.05, color='mistyrose')\n",
    "\n",
    "ax1.scatter(df_SGD['av_E_b_C_subsurf'],df_SGD['av_bulk_int_dist'],c=color_entire_dataset,s=marker_size)\n",
    "ax1.scatter(df_SGD_selected['av_E_b_C_subsurf'],df_SGD_selected['av_bulk_int_dist'],c=color_SG,s=marker_size)\n",
    "\n",
    "ax1.set_ylim(2.5,3.05)\n",
    "ax1.set_xlim(4,7.25)\n",
    "ax1.arrow(4.6685, 2.7, 0.5, 0, head_width=0.015, head_length=0.2, color=color_SG)\n",
    "ax1.arrow(5.8, 2.5659, 0, 0.06, head_width=0.10, head_length=0.03, color=color_SG)\n",
    "\n",
    "ax1.set_xlabel('$\\\\widebar{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$ (eV)')  \n",
    "ax1.set_ylabel('$\\\\widebar{d_{\\mathrm{closest}}}$ ($\\mathrm{\\AA}$)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task ⚠️\n",
    "Try the positive-mean-shift utility function, defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "    u(SG,\\widetilde{P})=\\frac{\\bar{Y}(SG)-\\bar{Y}(\\widetilde{P})}{Y_{\\mathrm{max}}(\\widetilde{P})-\\bar{Y}(\\widetilde{P})}.\n",
    "\\end{equation}\n",
    "\n",
    "and the negative-mean-shift utility function, defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "    u(SG,\\widetilde{P})=\\frac{-(\\bar{Y}(SG)-\\bar{Y}(\\widetilde{P}))}{Y_{\\mathrm{max}}(\\widetilde{P})-\\bar{Y}(\\widetilde{P})}.\n",
    "\\end{equation}\n",
    "\n",
    "In the equations above, $\\bar{Y}(SG)$ and $\\bar{Y}(\\widetilde{P})$ are the mean values of the distribution of the target in the SG and in the entire dataset, and $Y_{\\mathrm{max}}(\\widetilde{P})$ is the maximum value that the target assumes in the dataset.\n",
    "\n",
    "**Question:** How different are the SGs identified with the different utility functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the SGD job\n",
    "job_id='SGD_positive_mean'\n",
    "\n",
    "# Speficy SGD parameters\n",
    "# Number of thresholds (k in k-means clustering)\n",
    "n_clusters=20\n",
    "\n",
    "#Number of seeds used to initialize the SGD search algorithm (opportunistic pruning)\n",
    "n_seeds=50000\n",
    "\n",
    "#Number of SGD solutions to be printed\n",
    "n_results=5000\n",
    "\n",
    "#Check if old files exist for the specified job_id and remove them\n",
    "dirpath = os.path.join('./output/', job_id)\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "# Write input files\n",
    "# The utility function \"standard deviation reduction\" is chosen (\"PMM_SAMPLER\")\n",
    "write_input_SGD('./', \n",
    "            df_SGD.drop(['material_Temperature', 'time', 'S_ethylene', 'S_ethane','S_C4'], axis=1), \n",
    "            job_id, \n",
    "            n_clusters,\n",
    "            'EMM_SAMPLER',\n",
    "            'normalized_positive_mean_shift',\n",
    "            n_results, \n",
    "            n_seeds,\n",
    "            columns_to_extract[2],\n",
    "            1.0)\n",
    "# Run SGD  \n",
    "os.system('java -jar realkd-0.7.2-jar-with-dependencies.jar '+job_id+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with the SGD results\n",
    "file_results='./output/'+job_id+'/'+os.listdir('./output/'+job_id+'/')[0]+'/results/'+job_id+'_subgroup_analysis.json'\n",
    "\n",
    "# The results are stored in a dataframe that shows a list of SGs ranked by their quality-function values \n",
    "df_SGD_results=analyze_output_SGD(file_results)\n",
    "\n",
    "# Plot the distribution of target performance metrics in the entire dataset\n",
    "# and in the identified SG\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, constrained_layout=True, figsize=(6,6))\n",
    "\n",
    "# Apply the SG rules (constraints) to the dataset\n",
    "df_SGD_selected=df_SGD.query(df_SGD_results['constraints'][0])\n",
    "\n",
    "color_entire_dataset='black'\n",
    "color_SG='red'\n",
    "n_bins=20\n",
    "\n",
    "ax1.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax1.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "axins = inset_axes(ax1, width=\"65%\", height=\"35%\",loc=2)\n",
    "axins.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "axins.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "axins.set_ylim(0,40)\n",
    "\n",
    "ax2.hist(df_initial['S_ethylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax2.hist(df_SGD_selected['S_ethylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax3.hist(df_initial['S_ethane'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax3.hist(df_SGD_selected['S_ethane'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax4.hist(df_initial['S_C4'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax4.hist(df_SGD_selected['S_C4'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax1.set_ylabel('Counts')\n",
    "ax2.set_ylabel('Counts')\n",
    "ax3.set_ylabel('Counts')\n",
    "ax4.set_ylabel('Counts')\n",
    "\n",
    "ax1.set_xlabel('$X_{\\mathrm{acetylene}}$')\n",
    "ax2.set_xlabel('$S_{\\mathrm{ethylene}}$')\n",
    "ax3.set_xlabel('$S_{\\mathrm{ethane}}$')\n",
    "ax4.set_xlabel('$S_{\\mathrm{C4}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the SGD job\n",
    "job_id='SGD_negative_mean'\n",
    "\n",
    "# Speficy SGD parameters\n",
    "# Number of thresholds (k in k-means clustering)\n",
    "n_clusters=20\n",
    "\n",
    "#Number of seeds used to initialize the SGD search algorithm (opportunistic pruning)\n",
    "n_seeds=50000\n",
    "\n",
    "#Number of SGD solutions to be printed\n",
    "n_results=5000\n",
    "\n",
    "#Check if old files exist for the specified job_id and remove them\n",
    "dirpath = os.path.join('./output/', job_id)\n",
    "if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "    shutil.rmtree(dirpath)\n",
    "\n",
    "# Write input files\n",
    "# The utility function \"standard deviation reduction\" is chosen (\"PMM_SAMPLER\")\n",
    "write_input_SGD('./', \n",
    "            df_SGD.drop(['material_Temperature', 'time', 'S_ethylene', 'S_ethane','S_C4'], axis=1), \n",
    "            job_id, \n",
    "            n_clusters,\n",
    "            'EMM_SAMPLER',\n",
    "            'normalized_negative_mean_shift',\n",
    "            n_results, \n",
    "            n_seeds,\n",
    "            columns_to_extract[2],\n",
    "            1.0)\n",
    "# Run SGD  \n",
    "os.system('java -jar realkd-0.7.2-jar-with-dependencies.jar '+job_id+'.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with the SGD results\n",
    "file_results='./output/'+job_id+'/'+os.listdir('./output/'+job_id+'/')[0]+'/results/'+job_id+'_subgroup_analysis.json'\n",
    "\n",
    "# The results are stored in a dataframe that shows a list of SGs ranked by their quality-function values \n",
    "df_SGD_results=analyze_output_SGD(file_results)\n",
    "\n",
    "# Plot the distribution of target performance metrics in the entire dataset\n",
    "# and in the identified SG\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, constrained_layout=True, figsize=(6,6))\n",
    "\n",
    "# Apply the SG rules (constraints) to the dataset\n",
    "df_SGD_selected=df_SGD.query(df_SGD_results['constraints'][0])\n",
    "\n",
    "color_entire_dataset='black'\n",
    "color_SG='red'\n",
    "n_bins=20\n",
    "\n",
    "ax1.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax1.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "axins = inset_axes(ax1, width=\"65%\", height=\"35%\",loc=2)\n",
    "axins.hist(df_initial['X_acetylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "axins.hist(df_SGD_selected['X_acetylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "axins.set_ylim(0,40)\n",
    "\n",
    "ax2.hist(df_initial['S_ethylene'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax2.hist(df_SGD_selected['S_ethylene'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax3.hist(df_initial['S_ethane'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax3.hist(df_SGD_selected['S_ethane'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax4.hist(df_initial['S_C4'], color=color_entire_dataset, bins=n_bins, rwidth=0.8)\n",
    "ax4.hist(df_SGD_selected['S_C4'], color=color_SG, bins=n_bins, rwidth=0.8)\n",
    "\n",
    "ax1.set_ylabel('Counts')\n",
    "ax2.set_ylabel('Counts')\n",
    "ax3.set_ylabel('Counts')\n",
    "ax4.set_ylabel('Counts')\n",
    "\n",
    "ax1.set_xlabel('$X_{\\mathrm{acetylene}}$')\n",
    "ax2.set_xlabel('$S_{\\mathrm{ethylene}}$')\n",
    "ax3.set_xlabel('$S_{\\mathrm{ethane}}$')\n",
    "ax4.set_xlabel('$S_{\\mathrm{C4}}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Task ⚠️\n",
    "Use the cumulative Jensen-Shannon divergence utility function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training SISSO Models for Selectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first visualize the selectivity values as a function of time on stream for the datapoints selected in the SG\n",
    "\n",
    "# Path to the file with the SGD results of the publication\n",
    "job_id='SGD_results_publication'\n",
    "file_results='./output/'+job_id+'/'+os.listdir('./output/'+job_id+'/')[0]+'/results/'+job_id+'_subgroup_analysis.json'\n",
    "df_SGD_results=analyze_output_SGD(file_results)\n",
    "df_SGD_selected=df_SGD.query(df_SGD_results['constraints'][0])\n",
    "\n",
    "# Configure global plot font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Create grid of subplots (for three products at two temperatures)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "# Define visual properties for catalysts \n",
    "colors = ['grey'] * 3 + ['darkorange'] * 3 + ['brown'] * 3\n",
    "markers = ['s', '>', 'o'] * 3\n",
    "marker_size = 30\n",
    "\n",
    "# Loop over each of the 9 catalysts\n",
    "for i in range(9):    \n",
    "    # Get time-series data for current catalyst at 100°C and 150°C\n",
    "    cat_100 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_100']\n",
    "    cat_150 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_150']\n",
    "    \n",
    "    # Scatter plot for S_ethylene\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    \n",
    "    # Scatter plot for S_ethane\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    \n",
    "    # Scatter plot for S_C4\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "\n",
    "# Set axes limits\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.set_xlim(0, 406)\n",
    "\n",
    "ax1.set_ylim(-1.1, 1.5)\n",
    "ax2.set_ylim(-1.1, 1.5)\n",
    "ax3.set_ylim(0, 2.1)\n",
    "ax4.set_ylim(0, 2.1)\n",
    "ax5.set_ylim(0, 0.2)\n",
    "ax6.set_ylim(0, 0.2)\n",
    "\n",
    "# Set axis labels\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax3.set_ylabel('$S_{\\mathrm{C_2H_6}}$')\n",
    "ax5.set_ylabel('$S_{\\mathrm{C4}}$')\n",
    "ax5.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "ax6.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "\n",
    "# Tweak tick labels visibility for cleaner layout\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in [ax2, ax4, ax6]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Add subplot titles for temperature conditions\n",
    "ax1.set_title('$T_{\\mathrm{oven}} = 100\\,^\\circ\\mathrm{C}$')\n",
    "ax2.set_title('$T_{\\mathrm{oven}} = 150\\,^\\circ\\mathrm{C}$')\n",
    "\n",
    "# Add horizontal reference line at y=0 to the top row\n",
    "ax1.axhline(0, color='k', linewidth=0.5)\n",
    "ax2.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Add legend for catalysts (only once)\n",
    "ax2.legend(\n",
    "    labels=catalyst_list_caption[:9],\n",
    "    loc=(1.04, 0.05),\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    "    fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataset with the training data for SISSO is created based on the SG rules identified in the publication\n",
    "# It contains 539 data points, ca. 50% of the original dataset \n",
    "df_SISSO=df_initial.loc[(df_initial['T_reactor (C)'] > 75)\n",
    "                      & (df_initial['av_bulk_int_dist (A)'] >=2.5659)\n",
    "                      & (df_initial['av_E_b_C_subsurf (eV)'] >= 4.6685)]\n",
    "len(df_SISSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention ⚠️\n",
    "\n",
    "SISSO has two hyperparameters, the rung $q$ and the model dimensionality $D$. These hyperparameters are not learned during training and thus and thus need to be determined by evaluating the model performance in unseen data. For this purpose, a nested 5-fold cross-validation (CV) scheme is used: \n",
    "\n",
    "<img style=\"float: center;\" src=\"data/nested_CV.png\" width=650>\n",
    "\n",
    "\n",
    "The outer loop of the CV scheme is used to evaluate prediction errors. These are denoted *test errors* in the figure. The inner loop is used for evaluating the optimal model hyperparameters. The optimal set of hyperparameters is considered the one providing the lowest errors in the unseen data, denoted *validation errors*. In particular, we use the root mean squared error (RMSE) averaged over the five validation sets as our performance metric. Here, we consider $q=1,2$ and $D=1,2,3,4,5$. \n",
    "\n",
    "The sample indices correspoding to the nested 5-fold procedure are obtained as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_out=KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "\n",
    "indices_train_out=[]\n",
    "indices_test=[]\n",
    "\n",
    "for train_index,test_index in kf_out.split(df_SISSO):\n",
    "    indices_train_out.append(train_index)\n",
    "    indices_test.append(test_index)\n",
    "\n",
    "kf_in=KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "\n",
    "indices_train_in=[]\n",
    "indices_validation=[]\n",
    "\n",
    "for train_index,test_index in kf_in.split(df_SISSO.iloc[indices_train_out[0],:]):\n",
    "    indices_train_in.append(train_index)\n",
    "    indices_validation.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create input files for SISSO\n",
    "def write_input_SISSO(train,rung,dim,n_sis,n_res,ops,leave_out_ind,path,calculation_type):\n",
    "    \"\"\"Creates the directory and writes the input files (sisso.json and train.dat) for SISSO++\n",
    "    \n",
    "    Args:\n",
    "        train (pd.DataFrame): dataframe containing the data set\n",
    "        rung (int): number of iterations for operator application (e.g. 1, 2 or 3)\n",
    "        dim (int): descriptor dimension\n",
    "        n_sis (int): size of the SIS-selected feature spaces\n",
    "        n_res (int): number of residuals\n",
    "        ops (list): list of mathematical operators (str)\n",
    "        leave_out_ind (list): index of the materials to be left out from training, i.e., test materials\n",
    "        path (str): path of the directory to be created \n",
    "        calculation_type (str): type of calculation (e.g., regression or log_regression)\n",
    "    \"\"\"\n",
    "    rung_store = max(0, rung - 1)\n",
    "    rung_gen = 0 if rung < 3 else 1\n",
    "        \n",
    "    os.mkdir(path)\n",
    "    train.to_csv(f\"{path}/train.dat\")\n",
    "    prop_key=train.columns.values[0].split()[0]\n",
    "    input_file = {\n",
    "        'desc_dim':dim,\n",
    "        'n_sis_select':n_sis,\n",
    "        'max_rung':rung,\n",
    "        'n_rung_store':rung_store,\n",
    "        'n_residual':n_res,\n",
    "        'min_abs_feat_val': 1e-6,\n",
    "        'max_abs_feat_val': 1e6,\n",
    "        'data_file': 'train.dat',\n",
    "        'property_key': prop_key,\n",
    "        'n_rung_generate': rung_gen,\n",
    "        'leave_out_inds': leave_out_ind,\n",
    "        'n_models_store': 10,\n",
    "        'opset': ops, \n",
    "        \"param_opset\": [\n",
    "        \"exp\",\n",
    "        \"log\"], \n",
    "        'global_param_opt': 'True',\n",
    "        'calc_type': calculation_type,\n",
    "    }\n",
    "    with open(f\"{path}/sisso.json\",'w') as outfile:\n",
    "        json.dump(input_file, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speficy SISSO parameters\n",
    "\n",
    "# Set of operators utilized to create the analytical expressions\n",
    "operator_set = [\"add\", \n",
    "                \"sub\", \n",
    "                \"abs_diff\", \n",
    "                \"mult\", \n",
    "                \"div\", \n",
    "                \"inv\", \n",
    "                \"exp\", \n",
    "                \"sq\", \n",
    "                \"cb\", \n",
    "                \"sqrt\", \n",
    "                \"cbrt\", \n",
    "                \"log\", \n",
    "                \"abs\", \n",
    "                \"six_pow\",\n",
    "                \"neg_exp\"] \n",
    "\n",
    "# Number of residuals\n",
    "n_res=5\n",
    "\n",
    "#Number of model dimensions\n",
    "dimension=5\n",
    "\n",
    "#Size of subspaces of features selected by SIS\n",
    "n_sis=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create directories and write SISSO input files associated to the nested cross-validation scheme\n",
    "# We also train SISSO models utilizing the entire dataset of 539 data points \n",
    "\n",
    "#os.mkdir('./output/full_dataset')\n",
    "#for fold in [0,1,2,3,4]:\n",
    "#    os.mkdir('./output/fold_'+str(fold))\n",
    "        \n",
    "#for target in performance_targets[1:]:\n",
    "#    for rung in [1,2]:\n",
    "#        df_SISSO_outer_loop=df_SISSO[['material_Temperature']+[target]+['task']+features].copy().set_index('material_Temperature')\n",
    "#        write_input_SISSO(df_SISSO_outer_loop,\n",
    "#                        rung, dimension, n_sis, n_res, operator_set,\n",
    "#                        '[]',\n",
    "#                        './output/full_dataset/'+target+'_r'+str(rung),\n",
    "#                       'regression')\n",
    "#        for fold in [0,1,2,3,4]:\n",
    "#            write_input_SISSO(df_SISSO_outer_loop,\n",
    "#                        rung, dimension, n_sis, n_res, operator_set,\n",
    "#                        indices_test[fold].tolist(),\n",
    "#                        './output/fold_'+str(fold)+'/'+target+'_r'+str(rung),\n",
    "#                       'regression')\n",
    "            \n",
    "#            os.mkdir('./output/fold_'+str(fold)+'/'+target+'_r'+str(rung)+'_cv')\n",
    "#            for it in [0,1,2,3,4]:\n",
    "#                    write_input_SISSO(df_SISSO_outer_loop.iloc[indices_train_out[fold],:],\n",
    "#                                rung, dimension, n_sis, n_res, operator_set,\n",
    "#                                 indices_validation[it].tolist(),\n",
    "#                                 './output/fold_'+str(fold)+'/'+target+'_r'+str(rung)+'_cv/iter_'+str(it),\n",
    "#                                'regression')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will not run the SISSO algorithm, but we will rather read the output files of SISSO provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain the validation errors of SISSO models\n",
    "def get_rmse_vs_dim(path,path_cv,n_iter,dim,unit_length):\n",
    "    \"\"\"\n",
    "    reads SISSO++ output (sisso.out) and returns train and validation errors as a function of descriptor dimension\n",
    "    arguments: path(str): directory containing the output files obtained with the outer-loop data set splits\n",
    "               path_cv(str): directory containing the output files obtained with the inner-loop data set splits (cross-validation)\n",
    "               n_iter(int): number of CV iterations\n",
    "               dim(int): descriptor max dimension\n",
    "               unit_length(int): lenght of the property unit\n",
    "    \"\"\"\n",
    "    train_errors=[]\n",
    "    cv_errors=[]\n",
    "    avg_cv_errors=[]\n",
    "    std_cv_errors=[]\n",
    "    with open(path+'/sisso.out') as f:\n",
    "        data = f.readlines()\n",
    "        i = 0\n",
    "        for line in data:\n",
    "            if line.__contains__('Train'):\n",
    "                train_rmse =float(line.split()[2].split(';')[0])\n",
    "                train_errors.append(train_rmse)\n",
    "                i += 1\n",
    "    \n",
    "    for it in [*range(n_iter)]:\n",
    "        with open(path_cv+'/iter_'+str(it)+'/sisso.out') as f:\n",
    "            data = f.readlines()\n",
    "            i = 0\n",
    "            for line in data:\n",
    "                if line.__contains__('Train'):\n",
    "                    test_rmse = float(line.split()[6+(unit_length-1)])\n",
    "                    cv_errors.append([i, test_rmse])\n",
    "                    i += 1\n",
    "    for d in [*range(dim)]:\n",
    "        a=[]\n",
    "        for k in [*range(len(cv_errors))]:\n",
    "            if cv_errors[k][0] == d:\n",
    "                a.append(cv_errors[k][1])\n",
    "        avg_cv_errors.append(np.average(a))\n",
    "        std_cv_errors.append(np.std(a))\n",
    "                \n",
    "    return(train_errors, avg_cv_errors, std_cv_errors) \n",
    "\n",
    "# Function to obtain the predictions of SISSO models on the test sets\n",
    "def get_test_data(path,n_iter,rung,dim,prop):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_data=pd.DataFrame()\n",
    "    for it in [*range(n_iter)]:\n",
    "        d=pd.read_csv(path+'fold_'+str(it)+'/'+str(prop)+'_r'+str(rung)+'/models/test_dim_'+str(dim)+'_model_0.dat', comment='#', header=None)\n",
    "        test_data=pd.concat([test_data,d])\n",
    "    return(test_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the validation errors utilizing the output files provided in ./output/SISSO_results_publication\n",
    "\n",
    "# Set default font size for plots\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# X-axis values and style definitions\n",
    "x = [1, 2, 3, 4, 5]\n",
    "colors = ['', 'red', 'blue']  # rung 1: red, rung 2: blue\n",
    "labels = ['', '$q=1$', '$q=2$']\n",
    "\n",
    "# Loop through each performance target\n",
    "for target in performance_targets[1:]:\n",
    "    # Define y-axis upper limit as a fraction of the target's std deviation\n",
    "    std_of_target = np.std(df_SISSO[target]) * 0.6\n",
    "\n",
    "    # Create 1 row x 5 columns subplot grid, one per data fold\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 4), constrained_layout=True)\n",
    "\n",
    "    for fold, ax in enumerate(axes):\n",
    "        # Plot results for each rung (model complexity level)\n",
    "        for rung in [1, 2]:\n",
    "            # Build file path and load RMSE values\n",
    "            path = f'./output/SISSO_results_publication/fold_{fold}/{target}_r{rung}'\n",
    "            errors = get_rmse_vs_dim(path, path + '_cv', 5, 5, 1)\n",
    "\n",
    "            # Plot with error bars\n",
    "            ax.errorbar(x, errors[1], yerr=errors[2],\n",
    "                        color=colors[rung],\n",
    "                        marker='o',\n",
    "                        mfc=colors[rung],\n",
    "                        capsize=4,\n",
    "                        label=labels[rung])\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_xlim(0.5, 5.5)\n",
    "        ax.set_xticks([1, 2, 3, 4, 5])\n",
    "        ax.set_xlabel('$D$')  # D = descriptor dimension\n",
    "\n",
    "        # Y-axis settings\n",
    "        ax.set_ylim(0, std_of_target)\n",
    "        if fold == 0:\n",
    "            ax.set_ylabel('Cross-validation RMSE')\n",
    "            ax.set_title(target)\n",
    "        else:\n",
    "            ax.set_yticks([])  # Remove y-ticks from all but the first plot\n",
    "\n",
    "        # Add second Y-axis\n",
    "        ax_twin = ax.twinx()\n",
    "        ax_twin.set_ylim(0, 60)\n",
    "        #ax_twin.set_yticks([])\n",
    "        if fold == 4:\n",
    "            ax_twin.set_ylabel('Cross-validation RMSE / $\\sigma$ (%)')\n",
    "\n",
    "        # Add legend only in the first plot\n",
    "        if fold == 0:\n",
    "            ax.legend(loc='upper right', frameon=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task ⚠️\n",
    "\n",
    "**Question:** What hyperparameters would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test errors utilizing the output files provided in ./output/SISSO_results_publication\n",
    "\n",
    "# Plot style settings\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Optimal rung and descriptor dimension for each target, as identified based on the validation errors (above)\n",
    "optimal_rungs = [2, 2, 2]\n",
    "optimal_dimensions = [3, 3, 3]\n",
    "\n",
    "# Plot customization for boxplots and violin plots\n",
    "colors = ['lightblue']\n",
    "boxprops = {\"zorder\": 100, \"linewidth\": 1.5, \"edgecolor\": \"k\", \"facecolor\": \"none\"}\n",
    "whiskerprops = {\"zorder\": 100, \"color\": \"k\", \"linewidth\": 1.5}\n",
    "capprops = {\"zorder\": 100, \"color\": \"k\", \"linewidth\": 1.5}\n",
    "medianprops = {\"linewidth\": 1.5, \"color\": \"orange\", \"zorder\": 200}\n",
    "meanprops = {\n",
    "    \"marker\": \"x\", \"markersize\": 10.0,\n",
    "    \"markerfacecolor\": \"k\", \"markeredgecolor\": \"k\",\n",
    "    \"zorder\": 500\n",
    "}\n",
    "\n",
    "# Descriptor labels for each subplot\n",
    "xlabels = ['$S_{\\mathrm{C_2H_4}}$', '$S_{\\mathrm{C_2H_6}}$', '$S_{\\mathrm{C_4}}$']\n",
    "\n",
    "# Create a single-row, 3-column plot layout\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "# Loop over the three properties to generate subplots\n",
    "for i, ax in enumerate(axes):\n",
    "    # Get standard deviation of the target variable (for error normalization)\n",
    "    target = performance_targets[i + 1]\n",
    "    std_of_target = np.std(df_SISSO[target])\n",
    "\n",
    "    # Get prediction error data for the optimal model settings\n",
    "    test_data = get_test_data('./output/SISSO_results_publication/', 5, optimal_rungs[i], optimal_dimensions[i], target)\n",
    "    test_data[\"error\"] = abs(test_data[1] - test_data[2])\n",
    "    test_data[\"type\"] = 1  # Constant x-category\n",
    "\n",
    "    # Violin plot\n",
    "    sns.violinplot(\n",
    "        data=test_data, x=\"type\", y=\"error\",\n",
    "        inner=None, scale=\"area\", palette=colors,\n",
    "        alpha=1.0, linewidth=0.0, zorder=-2, ax=ax\n",
    "    )\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(\n",
    "        data=test_data, x=\"type\", y=\"error\",\n",
    "        showfliers=True, showmeans=True,\n",
    "        boxprops=boxprops, whiskerprops=whiskerprops,\n",
    "        capprops=capprops, medianprops=medianprops,\n",
    "        meanprops=meanprops, width=0.35, whis=(0.0, 95), ax=ax\n",
    "    )\n",
    "\n",
    "    # Axes formatting\n",
    "    ax.set_xticklabels([''], va='top', fontsize=16)\n",
    "    ax.set_ylim(0, std_of_target * 1.5)\n",
    "    ax.set_xlabel(xlabels[i])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Absolute Test Error')\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    # Secondary y-axis for percent-normalized view\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.set_ylim(0, 150)\n",
    "    if i == 2:\n",
    "        ax_twin.set_ylabel('Absolute Test Error/$\\mathrm{\\sigma}$ (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the errors for different materials and selectivity values, in the case of ethylene selectivity target\n",
    "\n",
    "# Load test data for ethylene selectivity prediction\n",
    "test_data = get_test_data('./output/SISSO_results_publication/', 5, 2, 3, 'S_ethylene')\n",
    "\n",
    "# Compute test errors\n",
    "test_data[\"abserror\"] = abs(test_data[1] - test_data[2])     # Absolute error\n",
    "test_data[\"error\"] = test_data[2] - test_data[1]             # Signed error\n",
    "\n",
    "# Extract catalyst identity for color coding\n",
    "test_data[\"labels\"] = test_data[0].str[:4]                   # First 4 characters e.g., 'PdAg'\n",
    "\n",
    "# Define color map and assign colors based on catalyst type\n",
    "color_map = {'PdAg': 'grey', 'PdAu': 'darkorange', 'PdCu': 'brown'}\n",
    "colors = test_data[\"labels\"].map(color_map)\n",
    "\n",
    "# Create side-by-side scatter plots ===\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n",
    "marker_size = 10\n",
    "\n",
    "# Plot 1: SISSO prediction vs true value (Parity plot)\n",
    "ax1.scatter(test_data[1], test_data[2], c=colors, s=marker_size)\n",
    "ax1.plot([-3, 2], [-3, 2], color='k', linestyle='--', linewidth=1)  # Diagonal reference line\n",
    "ax1.set_xlabel('$S_{\\mathrm{C_2H_4}}$')                             # True value\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}^{\\mathrm{SISSO}}$')            # Predicted value\n",
    "ax1.set_xlim(-2.6, 1)\n",
    "ax1.set_ylim(-2.6, 1)\n",
    "\n",
    "# Plot 2: Absolute error vs true value\n",
    "ax2.scatter(test_data[1], test_data[\"abserror\"], c=colors, s=marker_size)\n",
    "ax2.set_xlabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax2.set_ylabel('Absolute Test Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of model fit to the data \n",
    "# We look at the models trained on the entire dataset \n",
    "# at the optimal complexity identified by cross-validation\n",
    "targets=performance_targets[1:]\n",
    "for i in [0,1,2]:\n",
    "    df_fit=pd.read_csv('./output/SISSO_results_publication/full_dataset/'+targets[i]+'_r'+str(optimal_rungs[i])+'/models/train_dim_'+str(optimal_dimensions[i])+'_model_0.dat',\n",
    "                        comment='#',\n",
    "                        names=['material_Temperature_time',\n",
    "                            'target_true','target_fit',\n",
    "                            'feature_0','feature_1','feature_2']).set_index('material_Temperature_time')\n",
    "    df_SGD_selected[targets[i]+'_SISSO']=df_fit['target_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure global plot font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Create 3x2 grid of subplots (for three products at two temperatures)\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12, 9), constrained_layout=True)\n",
    "\n",
    "# Define visual properties for catalysts\n",
    "colors = ['grey'] * 3 + ['darkorange'] * 3 + ['brown'] * 3\n",
    "markers = ['s', '>', 'o'] * 3\n",
    "marker_size = 30\n",
    "\n",
    "# Loop over each of the 9 catalysts\n",
    "for i in range(9):    \n",
    "    # Get time-series data for current catalyst at 100°C and 150°C\n",
    "    cat_100 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_100']\n",
    "    cat_150 = df_SGD_selected.loc[df_SGD_selected['material_Temperature'] == catalyst_list[i] + '_150']\n",
    "    \n",
    "    # Scatter plot for S_ethylene\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax1.scatter(cat_100['time'], cat_100['S_ethylene_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax2.scatter(cat_150['time'], cat_150['S_ethylene_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    \n",
    "    # Scatter plot for S_ethane\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax3.scatter(cat_100['time'], cat_100['S_ethane_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax4.scatter(cat_150['time'], cat_150['S_ethane_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    \n",
    "    # Scatter plot for S_C4\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax5.scatter(cat_100['time'], cat_100['S_C4_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4'], color=colors[i], s=marker_size, marker=markers[i])\n",
    "    ax6.scatter(cat_150['time'], cat_150['S_C4_SISSO'], color=colors[i], s=marker_size, marker='x')\n",
    "\n",
    "# Set axes limits\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.set_xlim(0, 406)\n",
    "ax1.set_ylim(-1.5, 1.5)\n",
    "ax2.set_ylim(-1.5, 1.5)\n",
    "ax3.set_ylim(0, 2.1)\n",
    "ax4.set_ylim(0, 2.1)\n",
    "ax5.set_ylim(0, 0.2)\n",
    "ax6.set_ylim(0, 0.2)\n",
    "\n",
    "# Set axis labels\n",
    "ax1.set_ylabel('$S_{\\mathrm{C_2H_4}}$')\n",
    "ax3.set_ylabel('$S_{\\mathrm{C_2H_6}}$')\n",
    "ax5.set_ylabel('$S_{\\mathrm{C4}}$')\n",
    "ax5.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "ax6.set_xlabel('$t_{\\mathrm{OS}}$ (min)')\n",
    "\n",
    "# Tweak tick labels visibility for cleaner layout\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_xticklabels([])\n",
    "for ax in [ax2, ax4, ax6]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Add subplot titles for temperature conditions\n",
    "ax1.set_title('$T_{\\mathrm{oven}} = 100\\,^\\circ\\mathrm{C}$')\n",
    "ax2.set_title('$T_{\\mathrm{oven}} = 150\\,^\\circ\\mathrm{C}$')\n",
    "\n",
    "# Add horizontal reference line at y=0 to the top row\n",
    "ax1.axhline(0, color='k', linewidth=0.5)\n",
    "ax2.axhline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# Add legend for catalysts (only once)\n",
    "ax2.legend(\n",
    "    labels=['measured', 'SISSO'],\n",
    "    loc=(1.04, 0.05),\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    "    fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model expressions\n",
    "# We look at the models trained on the entire dataset \n",
    "# at the optimal complexity identified by cross-validation\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    print('\\n SISSO Model for ', targets[i])\n",
    "    with open('./output/SISSO_results_publication/full_dataset/'+targets[i]+'_r'+str(optimal_rungs[i])+'/models/train_dim_'+str(optimal_dimensions[i])+'_model_0.dat', 'r') as file:\n",
    "         for j, line in enumerate(file, start=1):\n",
    "            if j in [1,4,5,6,7]:\n",
    "                print(line, end='')\n",
    "            if j >= 7:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model expressions of the top-50 ranked models for ethylene selectivity\n",
    "for i in range(50):\n",
    "    print('\\n Top '+str(i)+' SISSO Model for ', targets[0])\n",
    "    with open('./output/SISSO_results_publication/full_dataset/'+targets[0]+'_r'+str(optimal_rungs[0])+'_50_output_models/models/train_dim_'+str(optimal_dimensions[0])+'_model_'+str(i)+'.dat', 'r') as file:\n",
    "         for j, line in enumerate(file, start=1):\n",
    "            if j in [1,3,4,5,6,7]:\n",
    "                print(line, end='')\n",
    "            if j >= 7:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exploiting the SGD and SISSO Models to Design New Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset of elemental properties \n",
    "df_elemental=pd.read_csv('./data/elemental_properties.csv').set_index('element')\n",
    "df_elemental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate descriptive parameters (primary features) for hypothetical materials\n",
    "# obtained with new elements mixed with palladium at different stoichiometries\n",
    "\n",
    "elements=df_elemental.index.tolist()\n",
    "elements.remove('Pd')\n",
    "\n",
    "# Chosen range of stoichiometries\n",
    "x_element=np.linspace(0.1, 0.9, 9).tolist()\n",
    "\n",
    "elemental_features=['IP', \n",
    "                    'EA', \n",
    "                    'PE',\n",
    "                    'bulk_int_dist', \n",
    "                    'E_coh', \n",
    "                    'B_0', \n",
    "                    'mu_C_critical_surf',\n",
    "                    'mu_C_critical_subsurf', \n",
    "                    'E_b_C_subsurf', \n",
    "                    'E_def_subsurf',\n",
    "                    'delta_M1_M2_subsurf', \n",
    "                    'BE_H_surf', \n",
    "                    'W_change_H',\n",
    "                    'd_band_center_surf', \n",
    "                    'BE_H_subsurf']\n",
    "\n",
    "rows = []\n",
    "\n",
    "for element in elements:\n",
    "    for x in x_element:\n",
    "        x_str = f\"{x:.1f}\" \n",
    "        x_comp_str = f\"{(1-x):.1f}\"\n",
    "        row={}\n",
    "        row['material']='Pd'+x_comp_str+element+x_str\n",
    "        for parameter in elemental_features:\n",
    "            feature_value=df_elemental.at[element, parameter]*x+df_elemental.at['Pd', parameter]*(1-x)\n",
    "            row['av_'+parameter]=feature_value\n",
    "        rows.append(row)\n",
    "           \n",
    "df_new_bimetallic = pd.DataFrame(rows).set_index('material')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuzalize the hypothetical materials in the coordinates of the key materials-parameters identified by SGD\n",
    "# The SG rules are also shown\n",
    "\n",
    "fig, (ax1) = plt.subplots(1,1, constrained_layout=True, figsize=(4,4))\n",
    "marker_size=30\n",
    "ax1.vlines(4.6685,2.5659,3.05,color='red',linestyle='dashed')\n",
    "ax1.hlines(2.5659,4.6685,9,color='red',linestyle='dashed')\n",
    "ax1.fill_between([4.6685,9], 2.5659, 3.05, color='mistyrose')\n",
    "ax1.fill([7.8,6.05,4.33], [2.753,2.556,2.889], color='orange',  edgecolor='orange')\n",
    "\n",
    "ax1.scatter(df_SGD['av_E_b_C_subsurf'],df_SGD['av_bulk_int_dist'],c=color_entire_dataset,s=marker_size)\n",
    "ax1.scatter(df_SGD_selected['av_E_b_C_subsurf'],df_SGD_selected['av_bulk_int_dist'],c=color_SG,s=marker_size)\n",
    "ax1.scatter(df_new_bimetallic['av_E_b_C_subsurf'],df_new_bimetallic['av_bulk_int_dist'],c='grey',s=marker_size)\n",
    "\n",
    "ax1.set_ylim(2.4,3.05)\n",
    "ax1.set_xlim(4,8.5)\n",
    "ax1.arrow(4.6685, 2.7, 0.5, 0, head_width=0.015, head_length=0.2, color=color_SG)\n",
    "ax1.arrow(5.8, 2.5659, 0, 0.06, head_width=0.10, head_length=0.03, color=color_SG)\n",
    "\n",
    "ax1.set_xlabel('$\\\\widebar{E_{\\mathrm{b,C}}^{\\mathrm{sub}}}$ (eV)')  \n",
    "ax1.set_ylabel('$\\\\widebar{d_{\\mathrm{closest}}}$ ($\\mathrm{\\AA}$)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the SISSO model for ethylene selectivity\n",
    "def evaluate_SISSO_model_ethylene_selectivity(av_W_change_H,\n",
    "                                              av_d_band_center_surf,\n",
    "                                              av_BE_H_surf, \n",
    "                                              av_E_def_subsurf, \n",
    "                                              total_metal_loading, \n",
    "                                              particle_diameter,\n",
    "                                              av_BE_H_subsurf,\n",
    "                                              time, \n",
    "                                              temperature):\n",
    "    \n",
    "    if temperature == 150:\n",
    "        a=[4.813130462568657e-07, 3.727722063287428e+01,  -2.850231650770238e+00, -8.362104387720386e-02]\n",
    "    if temperature == 100:\n",
    "        a=[1.263789736634742e-06, 5.269016813835863e+01,  -2.661969356874947e+00, -1.704277305893994e-01]\n",
    "    \n",
    "    term_1=a[0]*(time / av_W_change_H) / (np.abs(av_d_band_center_surf - av_BE_H_surf))\n",
    "    term_2=a[1]*(av_E_def_subsurf * total_metal_loading * particle_diameter)\n",
    "    term_3=a[2]*(np.exp(8.365003e-04*((time+3.592461e+02) / (av_BE_H_subsurf+1.384560e+00))))\n",
    "    selectivity=term_1+term_2+term_3+a[3]\n",
    "    return(selectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predicted ethylene selectivity for new hypothetical bimetallic materials\n",
    "\n",
    "# The experimental parameters entering the SISSO model are unknown for new materials\n",
    "# We assume that the metal loading and mean particle diameter of these materials are\n",
    "# equal to the mean values among the materials in the training set\n",
    "mean_total_metal_loading=0.011755658627087199\n",
    "mean_particle_diameter=5.667903525046382\n",
    "\n",
    "# One temperature and two time-on-stream values are chosen\n",
    "temperature = 150  \n",
    "time = [40,400] \n",
    "\n",
    "# Chosen range of stoichiometries\n",
    "x_element=[0.45, 0.55, 0.65, 0.75, 0.85, 0.90]\n",
    "\n",
    "rows = []\n",
    "selectivities_40_min = []\n",
    "selectivities_400_min = []\n",
    "\n",
    "for element in elements:\n",
    "    selectivity_40_min=[]\n",
    "    selectivity_400_min=[]\n",
    "    for x in x_element:\n",
    "        x_str = f\"{x:.1f}\" \n",
    "        x_comp_str = f\"{(1-x):.1f}\"\n",
    "        row={}\n",
    "        row['material']='Pd'+x_comp_str+element+x_str\n",
    "        for parameter in elemental_features:\n",
    "            feature_value=df_elemental.at[element, parameter]*x+df_elemental.at['Pd', parameter]*(1-x)\n",
    "            row['av_'+parameter]=feature_value\n",
    "        row['S_ethylene_SISSO_40min_150C']=evaluate_SISSO_model_ethylene_selectivity(row['av_W_change_H'],\n",
    "                                                                                     row['av_d_band_center_surf'],\n",
    "                                                                                     row['av_BE_H_surf'],\n",
    "                                                                                     row['av_E_def_subsurf'],\n",
    "                                                                                     mean_total_metal_loading,\n",
    "                                                                                     mean_particle_diameter,\n",
    "                                                                                     row['av_BE_H_subsurf'],\n",
    "                                                                                     time[0],\n",
    "                                                                                     temperature)\n",
    "        row['S_ethylene_SISSO_400min_150C']=evaluate_SISSO_model_ethylene_selectivity(row['av_W_change_H'],\n",
    "                                                                                      row['av_d_band_center_surf'],\n",
    "                                                                                      row['av_BE_H_surf'],\n",
    "                                                                                      row['av_E_def_subsurf'],\n",
    "                                                                                      mean_total_metal_loading,\n",
    "                                                                                      mean_particle_diameter,\n",
    "                                                                                      row['av_BE_H_subsurf'],\n",
    "                                                                                      time[1],\n",
    "                                                                                      temperature)\n",
    "        rows.append(row)\n",
    "        selectivity_40_min.append(row['S_ethylene_SISSO_40min_150C'])\n",
    "        selectivity_400_min.append(row['S_ethylene_SISSO_400min_150C'])\n",
    "    selectivities_40_min.append(selectivity_40_min)\n",
    "    selectivities_400_min.append(selectivity_400_min)\n",
    "\n",
    "df_new_bimetallic = pd.DataFrame(rows).set_index('material')\n",
    "\n",
    "x_element_labels=[45, 55, 65, 75, 85, 90]\n",
    "    \n",
    "fig, (ax1,ax2) = plt.subplots(1,2, constrained_layout=True, figsize=(8,4))\n",
    "im = ax1.imshow(selectivities_40_min ,cmap='viridis',vmin=-1.35, vmax=0.96, aspect='auto')\n",
    "im2 = ax2.imshow(selectivities_400_min ,cmap='viridis',vmin=-1.35, vmax=0.96, aspect='auto')\n",
    "ax1.set_ylabel('element')\n",
    "ax1.set_xlabel('$x_{\\mathrm{element}}$ (%)')\n",
    "ax1.set_xticks(ticks=[0,1,2,3,4,5], labels=x_element_labels)\n",
    "ax1.set_yticks(ticks=[0,1,2,3,4,5,6,7,8], labels=elements)\n",
    "fig.colorbar(im2, ax=ax2, label='Predicted $S_{\\mathrm{C_2H_4}}^{\\mathrm{SISSO}}$', fraction=0.050, pad=0.05)\n",
    "ax2.set_xlabel('$x_{\\mathrm{element}}$ (%)')\n",
    "ax2.set_xticks(ticks=[0,1,2,3,4,5], labels=x_element_labels)\n",
    "ax2.set_yticks(ticks=[0,1,2,3,4,5,6,7,8], labels='')\n",
    "ax1.set_title('$t_{\\mathrm{OS}}$ = 40 min')\n",
    "ax2.set_title('$t_{\\mathrm{OS}}$ = 400 min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Experimental Verification of SISSO Model Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_new = pd.read_csv('./data/performance_data_new_materials.csv')\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "size = 20\n",
    "time = np.arange(1, 400, 15)\n",
    "\n",
    "# Define composition and physical parameters\n",
    "compositions = [\n",
    "    {'label': 'Pd_Ag_1_12_150', 'comp': {'Pd': 1/13, 'Ag': 12/13}, 'd': 6.03, 'm': 0.0153, 'ax': ax1, 'title': 'Pd$_1$Ag$_{12}$'},\n",
    "    {'label': 'Pd_Ag_1_15_150', 'comp': {'Pd': 1/16, 'Ag': 15/16}, 'd': 7.04, 'm': 0.0161, 'ax': ax2, 'title': 'Pd$_1$Ag$_{15}$'},\n",
    "    {'label': 'Pd_Ag_Cu_1_5_1_150', 'comp': {'Pd': 1/7, 'Ag': 5/7, 'Cu': 1/7}, 'd': 5.80, 'm': 0.0145, 'ax': ax3, 'title': 'Pd$_1$Ag$_5$Cu$_1$'}\n",
    "]\n",
    "\n",
    "# Loop over each composition\n",
    "for cond in compositions:\n",
    "    comp = cond['comp']\n",
    "    ax = cond['ax']\n",
    "    \n",
    "    # Compute weighted average properties\n",
    "    av_W_change_H = sum(comp[e] * df_elemental.at[e, 'W_change_H'] for e in comp)\n",
    "    av_d_band_center_surf = sum(comp[e] * df_elemental.at[e, 'd_band_center_surf'] for e in comp)\n",
    "    av_BE_H_surf = sum(comp[e] * df_elemental.at[e, 'BE_H_surf'] for e in comp)\n",
    "    av_E_def_subsurf = sum(comp[e] * df_elemental.at[e, 'E_def_subsurf'] for e in comp)\n",
    "    av_BE_H_subsurf = sum(comp[e] * df_elemental.at[e, 'BE_H_subsurf'] for e in comp)\n",
    "\n",
    "    # Predict using SISSO model\n",
    "    predictions = []\n",
    "    for t in time:\n",
    "        y = evaluate_SISSO_model_ethylene_selectivity(\n",
    "            av_W_change_H,\n",
    "            av_d_band_center_surf,\n",
    "            av_BE_H_surf,\n",
    "            av_E_def_subsurf,\n",
    "            cond['m'],\n",
    "            cond['d'],\n",
    "            av_BE_H_subsurf,\n",
    "            t,\n",
    "            150\n",
    "        )\n",
    "        predictions.append(y)\n",
    "    \n",
    "    # Plot SISSO predictions\n",
    "    ax.scatter(time, predictions, color='red', s=size, marker='s')\n",
    "    \n",
    "    # Plot experimental data\n",
    "    data = data_new[data_new['material_Temperature'] == cond['label']]\n",
    "    ax.scatter(data['time (min)'], data['X_acetylene'], color='k', s=size, marker='x')\n",
    "    ax.scatter(data['time (min)'], data['S_ethylene'], color='blue', s=size, marker='s')\n",
    "    \n",
    "    # Axis formatting\n",
    "    ax.set_xlim(0, 400)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.hlines(0, 0, 400, color='k', linewidth=0.5)\n",
    "    ax.set_xlabel('$t_{\\mathrm{OS}}$(min)')\n",
    "    ax.set_title(cond['title'])\n",
    "\n",
    "# Add common y-label and clean up redundant ticks\n",
    "ax1.set_ylabel('$S$ or $X$, $T_{\\mathrm{oven}}=150\\degree$C')\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Additional Resources\n",
    "\n",
    "Here are references of other works utilizing the SGD and SISSO approach. Each of them is associated with a dedicated jupyter notebook.\n",
    "\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> L. Foppa and L. M. Ghiringhelli: <span style=\"font-style: italic;\">Identifying Outstanding Transition-Metal-Alloy Heterogeneous Catalysts for the Oxygen Reduction and Evolution Reactions via Subgroup Discovery </span> <a href=\"https://link.springer.com/article/10.1007/s11244-021-01502-4\" target=\"_top\">Topics in Catalysis 65, 196 (2022)</a> <a href=\"https://nomad-lab.eu/AItutorials/sgd_alloys_oxygen_reduction_evolution\" target=\"_top\">[Jupyter Notebook]</a>\n",
    "</div>\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\"> L. Foppa, C. Sutton, L. M. Ghiringhelli, S. De, P. Loser, S. A. Schunk, A. Schafer, M. Scheffler: <span style=\"font-style: italic;\">Learning Design Rules for Selective Oxidation Catalysts from High-Throughput Experimentation and Artificial Intelligence </span> <a href=\"https://doi.org/10.1021/acscatal.1c04793\" target=\"_top\">ACS Catalysis 12, 2223 (2022) </a> </span> <a href=\"https://nomad-lab.eu/AItutorials/SGD_Propylene_Oxidation_HTE\" target=\"_top\">[Jupyter Notebook]</a>\n",
    "</div>\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "L. Foppa and M. Scheffler: <span style=\"font-style: italic;\">Coherent Collections of Rules Describing Exceptional Materials Identified with a Multi-Objective Optimization of Subgroups</span> <a href=\"https://arxiv.org/abs/2403.18437#\" target=\"_blank\">arXiv, 2403.18437 (2024)</a>  </span> <a href=\"https://github.com/lfoppa/Multi-objective-optimization-of-subgroups\" target=\"_top\">[Jupyter Notebook]</a>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"padding: 1ex; margin-top: 1ex; margin-bottom: 1ex; border-style: dotted; border-width: 1pt; border-color: blue; border-radius: 3px;\">\n",
    "L. Foppa, T. A. R. Purcell, S. V. Levchenko, M. Scheffler, L. M. Ghiringhelli: <span style=\"font-style: italic;\">Hierarchical Symbolic Regression for Identifying Key Physical Parameters Correlated with Bulk Properties of Perovskites </span> <a href=\"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.129.055301\" target=\"_blank\">Physical Review Letters 129, 055301 (2022) </a>  </span> <a href=\"https://nomad-lab.eu/aitoolkit/hierarchical_sisso\" target=\"_top\">[Jupyter Notebook]</a>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
